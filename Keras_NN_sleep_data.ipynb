{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "ONRu7vdBwYeZ",
    "outputId": "05705115-47c8-4339-9c36-57fcaa23e142",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckyTqrQtJqDF"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from keras import optimizers\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_KADF-vKE8Y3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "HWJ0INZVFAnf",
    "outputId": "e2b904c4-701b-4725-93dc-85129c69e272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14327243075166937544\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7498691980714230939\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4621021758815028186\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15956161332\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6174699584092254344\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "RXaMUu8_Jkyd",
    "outputId": "6e34353d-729e-4687-9bec-00345519c905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All patients\n",
      "     time         x         y         z  heartbeat  label\n",
      "0    0.0  0.184021  0.679169 -0.476990       87.0     -1\n",
      "1   30.0 -0.301010  0.805710  0.487167       95.0     -1\n",
      "2   60.0 -0.323517  0.923447  0.146362       84.0     -1\n",
      "3   90.0 -0.509674  0.855102 -0.049118       85.0     -1\n",
      "4  120.0 -0.387756  0.919067  0.023758       82.0     -1\n",
      "All patients shuffled\n",
      "           time         x         y         z  heartbeat  label\n",
      "11138  12960.0 -0.489136 -0.721283 -0.482956       64.0      2\n",
      "14992  12030.0 -0.111282 -0.923660  0.346405       63.0      0\n",
      "20565   7470.0 -0.159134  0.872864 -0.453384       61.0      2\n",
      "23314   4680.0 -0.586410  0.362381 -0.729324       72.0      3\n",
      "2226    6990.0 -0.502884 -0.533966  0.672272       65.0      2\n",
      "Patients data size (25781, 6)\n",
      "\n",
      "Patients data normalized heartbeat\n",
      "           time         x         y         z  heartbeat  label\n",
      "11138  12960.0 -0.489136 -0.721283 -0.482956   0.258427      2\n",
      "14992  12030.0 -0.111282 -0.923660  0.346405   0.247191      0\n",
      "20565   7470.0 -0.159134  0.872864 -0.453384   0.224719      2\n",
      "23314   4680.0 -0.586410  0.362381 -0.729324   0.348315      3\n",
      "2226    6990.0 -0.502884 -0.533966  0.672272   0.269663      2\n",
      "X data \n",
      " [[-0.4891357  -0.721283   -0.4829559   0.25842697]\n",
      " [-0.1112823  -0.9236603   0.346405    0.24719101]\n",
      " [-0.1591339   0.8728638  -0.4533844   0.2247191 ]\n",
      " [-0.5864105   0.362381   -0.7293243   0.34831461]\n",
      " [-0.5028839  -0.5339661   0.6722717   0.26966292]]\n",
      "Y data \n",
      " [2 0 2 3 2]\n",
      "4\n",
      "input_shape 4\n",
      "x train shape (20624, 4)\n",
      "(5157, 4)\n"
     ]
    }
   ],
   "source": [
    "path = \"/content/drive/My Drive/Sleep data\"\n",
    "filename_read = os.path.join(path, \"All_data_patients_correct.csv\")\n",
    "patient_all = pd.read_csv(filename_read)\n",
    "PAL = patient_all\n",
    "print(\"All patients\\n\", PAL.head())\n",
    "PAL = shuffle(PAL)\n",
    "print(\"All patients shuffled\\n\",PAL.head())\n",
    "print(\"Patients data size\", PAL.shape)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "PAL[['heartbeat']] = min_max_scaler.fit_transform(PAL[['heartbeat']].values)\n",
    "\n",
    "print(\"\\nPatients data normalized heartbeat\\n\", PAL.head())\n",
    "\n",
    "result = []\n",
    "for x in PAL.columns:\n",
    "    if x != 'label':\n",
    "        result.append(x)\n",
    "\n",
    "X = PAL[result].values\n",
    "X_with_time = X\n",
    "X = np.delete(X,0,1)\n",
    "y = PAL['label'].values\n",
    "print(\"X data \\n\", X[0:5])\n",
    "\n",
    "print(\"Y data \\n\", y[0:5])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\n",
    "X_train_time, X_test_time, y_train_time, y_test_time = train_test_split(X_with_time, y, test_size = 0.2, random_state = 42)\n",
    "#smt = SMOTE()\n",
    "#X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "one_hot = np.identity(7)\n",
    "train_labels_one_hot = []\n",
    "train_labels_one_hot_time = []\n",
    "test_labels_one_hot = []\n",
    "test_labels_one_hot_time = []\n",
    "for i in range(y_train.shape[0]):\n",
    "    train_labels_one_hot.append(one_hot[y_train[i]])   \n",
    "    train_labels_one_hot_time.append(one_hot[y_train_time[i]])\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    test_labels_one_hot.append(one_hot[y_test[i]]) \n",
    "    test_labels_one_hot_time.append(one_hot[y_test_time[i]])\n",
    "print(X_train.shape[1])\n",
    "\n",
    "#X_train_reshaped = X_train.reshape(32*32*3, 73257)\n",
    "#X_test_reshaped = X_test.reshape(32*32*3, 26032)\n",
    "input_shape = X_train.shape[1]\n",
    "input_shape_time = X_train_time.shape[1]\n",
    "print('input_shape', input_shape)\n",
    "print(\"x train shape\", X_train.shape)\n",
    "\n",
    "x_val = X_test\n",
    "y_val = np.array(test_labels_one_hot)\n",
    "x_val_time = X_test_time\n",
    "y_val_time = np.array(test_labels_one_hot_time)\n",
    "print(x_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3HZKTty3Jky3",
    "outputId": "053d995a-6efb-450b-85f5-64bd33a2b8b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Keras\n",
      "\n",
      "Train on 20624 samples, validate on 5157 samples\n",
      "Epoch 1/300\n",
      " - 5s - loss: 1.5232 - acc: 0.4809 - val_loss: 1.4638 - val_acc: 0.4842\n",
      "Epoch 2/300\n",
      " - 4s - loss: 1.4613 - acc: 0.4819 - val_loss: 1.4484 - val_acc: 0.4842\n",
      "Epoch 3/300\n",
      " - 4s - loss: 1.4479 - acc: 0.4817 - val_loss: 1.4374 - val_acc: 0.4836\n",
      "Epoch 4/300\n",
      " - 4s - loss: 1.4413 - acc: 0.4819 - val_loss: 1.4322 - val_acc: 0.4838\n",
      "Epoch 5/300\n",
      " - 4s - loss: 1.4368 - acc: 0.4824 - val_loss: 1.4354 - val_acc: 0.4842\n",
      "Epoch 6/300\n",
      " - 4s - loss: 1.4317 - acc: 0.4820 - val_loss: 1.4275 - val_acc: 0.4830\n",
      "Epoch 7/300\n",
      " - 4s - loss: 1.4273 - acc: 0.4831 - val_loss: 1.4229 - val_acc: 0.4828\n",
      "Epoch 8/300\n",
      " - 4s - loss: 1.4256 - acc: 0.4820 - val_loss: 1.4169 - val_acc: 0.4821\n",
      "Epoch 9/300\n",
      " - 4s - loss: 1.4228 - acc: 0.4832 - val_loss: 1.4211 - val_acc: 0.4830\n",
      "Epoch 10/300\n",
      " - 4s - loss: 1.4214 - acc: 0.4836 - val_loss: 1.4174 - val_acc: 0.4836\n",
      "Epoch 11/300\n",
      " - 4s - loss: 1.4207 - acc: 0.4837 - val_loss: 1.4171 - val_acc: 0.4815\n",
      "Epoch 12/300\n",
      " - 4s - loss: 1.4163 - acc: 0.4843 - val_loss: 1.4109 - val_acc: 0.4826\n",
      "Epoch 13/300\n",
      " - 4s - loss: 1.4180 - acc: 0.4835 - val_loss: 1.4132 - val_acc: 0.4828\n",
      "Epoch 14/300\n",
      " - 4s - loss: 1.4169 - acc: 0.4826 - val_loss: 1.4080 - val_acc: 0.4836\n",
      "Epoch 15/300\n",
      " - 4s - loss: 1.4153 - acc: 0.4830 - val_loss: 1.4054 - val_acc: 0.4832\n",
      "Epoch 16/300\n",
      " - 4s - loss: 1.4154 - acc: 0.4832 - val_loss: 1.4071 - val_acc: 0.4817\n",
      "Epoch 17/300\n",
      " - 4s - loss: 1.4126 - acc: 0.4854 - val_loss: 1.4088 - val_acc: 0.4811\n",
      "Epoch 18/300\n",
      " - 4s - loss: 1.4116 - acc: 0.4829 - val_loss: 1.4018 - val_acc: 0.4848\n",
      "Epoch 19/300\n",
      " - 4s - loss: 1.4102 - acc: 0.4846 - val_loss: 1.4028 - val_acc: 0.4838\n",
      "Epoch 20/300\n",
      " - 4s - loss: 1.4105 - acc: 0.4846 - val_loss: 1.4003 - val_acc: 0.4844\n",
      "Epoch 21/300\n",
      " - 4s - loss: 1.4090 - acc: 0.4843 - val_loss: 1.4017 - val_acc: 0.4795\n",
      "Epoch 22/300\n",
      " - 4s - loss: 1.4089 - acc: 0.4832 - val_loss: 1.3974 - val_acc: 0.4819\n",
      "Epoch 23/300\n",
      " - 4s - loss: 1.4077 - acc: 0.4855 - val_loss: 1.3977 - val_acc: 0.4823\n",
      "Epoch 24/300\n",
      " - 4s - loss: 1.4068 - acc: 0.4848 - val_loss: 1.4026 - val_acc: 0.4826\n",
      "Epoch 25/300\n",
      " - 4s - loss: 1.4078 - acc: 0.4844 - val_loss: 1.3985 - val_acc: 0.4821\n",
      "Epoch 26/300\n",
      " - 4s - loss: 1.4056 - acc: 0.4854 - val_loss: 1.3951 - val_acc: 0.4830\n",
      "Epoch 27/300\n",
      " - 4s - loss: 1.4048 - acc: 0.4844 - val_loss: 1.3921 - val_acc: 0.4811\n",
      "Epoch 28/300\n",
      " - 4s - loss: 1.4033 - acc: 0.4855 - val_loss: 1.3918 - val_acc: 0.4850\n",
      "Epoch 29/300\n",
      " - 4s - loss: 1.4027 - acc: 0.4846 - val_loss: 1.3906 - val_acc: 0.4848\n",
      "Epoch 30/300\n",
      " - 4s - loss: 1.4018 - acc: 0.4856 - val_loss: 1.3933 - val_acc: 0.4811\n",
      "Epoch 31/300\n",
      " - 4s - loss: 1.4011 - acc: 0.4848 - val_loss: 1.3927 - val_acc: 0.4819\n",
      "Epoch 32/300\n",
      " - 4s - loss: 1.3999 - acc: 0.4860 - val_loss: 1.3985 - val_acc: 0.4883\n",
      "Epoch 33/300\n",
      " - 4s - loss: 1.3976 - acc: 0.4873 - val_loss: 1.3890 - val_acc: 0.4834\n",
      "Epoch 34/300\n",
      " - 4s - loss: 1.3987 - acc: 0.4878 - val_loss: 1.3885 - val_acc: 0.4854\n",
      "Epoch 35/300\n",
      " - 4s - loss: 1.3958 - acc: 0.4872 - val_loss: 1.3874 - val_acc: 0.4902\n",
      "Epoch 36/300\n",
      " - 4s - loss: 1.3972 - acc: 0.4882 - val_loss: 1.3847 - val_acc: 0.4859\n",
      "Epoch 37/300\n",
      " - 4s - loss: 1.3955 - acc: 0.4872 - val_loss: 1.3827 - val_acc: 0.4883\n",
      "Epoch 38/300\n",
      " - 4s - loss: 1.3959 - acc: 0.4874 - val_loss: 1.3821 - val_acc: 0.4832\n",
      "Epoch 39/300\n",
      " - 4s - loss: 1.3931 - acc: 0.4888 - val_loss: 1.3829 - val_acc: 0.4871\n",
      "Epoch 40/300\n",
      " - 4s - loss: 1.3935 - acc: 0.4897 - val_loss: 1.3819 - val_acc: 0.4869\n",
      "Epoch 41/300\n",
      " - 4s - loss: 1.3924 - acc: 0.4912 - val_loss: 1.3830 - val_acc: 0.4898\n",
      "Epoch 42/300\n",
      " - 4s - loss: 1.3920 - acc: 0.4901 - val_loss: 1.3820 - val_acc: 0.4865\n",
      "Epoch 43/300\n",
      " - 4s - loss: 1.3902 - acc: 0.4919 - val_loss: 1.3789 - val_acc: 0.4914\n",
      "Epoch 44/300\n",
      " - 4s - loss: 1.3876 - acc: 0.4927 - val_loss: 1.3870 - val_acc: 0.4993\n",
      "Epoch 45/300\n",
      " - 4s - loss: 1.3917 - acc: 0.4915 - val_loss: 1.3755 - val_acc: 0.4904\n",
      "Epoch 46/300\n",
      " - 4s - loss: 1.3892 - acc: 0.4920 - val_loss: 1.3739 - val_acc: 0.4966\n",
      "Epoch 47/300\n",
      " - 4s - loss: 1.3880 - acc: 0.4923 - val_loss: 1.3811 - val_acc: 0.4890\n",
      "Epoch 48/300\n",
      " - 4s - loss: 1.3871 - acc: 0.4923 - val_loss: 1.3723 - val_acc: 0.4933\n",
      "Epoch 49/300\n",
      " - 4s - loss: 1.3874 - acc: 0.4928 - val_loss: 1.3717 - val_acc: 0.4894\n",
      "Epoch 50/300\n",
      " - 4s - loss: 1.3856 - acc: 0.4920 - val_loss: 1.3812 - val_acc: 0.4865\n",
      "Epoch 51/300\n",
      " - 4s - loss: 1.3886 - acc: 0.4912 - val_loss: 1.3680 - val_acc: 0.4949\n",
      "Epoch 52/300\n",
      " - 4s - loss: 1.3824 - acc: 0.4941 - val_loss: 1.3666 - val_acc: 0.4892\n",
      "Epoch 53/300\n",
      " - 4s - loss: 1.3877 - acc: 0.4926 - val_loss: 1.3693 - val_acc: 0.4877\n",
      "Epoch 54/300\n",
      " - 4s - loss: 1.3820 - acc: 0.4928 - val_loss: 1.3671 - val_acc: 0.4890\n",
      "Epoch 55/300\n",
      " - 4s - loss: 1.3846 - acc: 0.4941 - val_loss: 1.3714 - val_acc: 0.4937\n",
      "Epoch 56/300\n",
      " - 4s - loss: 1.3805 - acc: 0.4966 - val_loss: 1.3636 - val_acc: 0.4925\n",
      "Epoch 57/300\n",
      " - 4s - loss: 1.3809 - acc: 0.4952 - val_loss: 1.3684 - val_acc: 0.4951\n",
      "Epoch 58/300\n",
      " - 4s - loss: 1.3795 - acc: 0.4948 - val_loss: 1.3682 - val_acc: 0.4956\n",
      "Epoch 59/300\n",
      " - 4s - loss: 1.3795 - acc: 0.4970 - val_loss: 1.3591 - val_acc: 0.4908\n",
      "Epoch 60/300\n",
      " - 4s - loss: 1.3751 - acc: 0.4997 - val_loss: 1.3613 - val_acc: 0.4974\n",
      "Epoch 61/300\n",
      " - 4s - loss: 1.3765 - acc: 0.4985 - val_loss: 1.3594 - val_acc: 0.4935\n",
      "Epoch 62/300\n",
      " - 4s - loss: 1.3756 - acc: 0.4982 - val_loss: 1.3556 - val_acc: 0.4889\n",
      "Epoch 63/300\n",
      " - 4s - loss: 1.3760 - acc: 0.4957 - val_loss: 1.3568 - val_acc: 0.4976\n",
      "Epoch 64/300\n",
      " - 4s - loss: 1.3747 - acc: 0.4984 - val_loss: 1.3647 - val_acc: 0.4906\n",
      "Epoch 65/300\n",
      " - 4s - loss: 1.3746 - acc: 0.4969 - val_loss: 1.3542 - val_acc: 0.4921\n",
      "Epoch 66/300\n",
      " - 4s - loss: 1.3726 - acc: 0.4994 - val_loss: 1.3511 - val_acc: 0.4947\n",
      "Epoch 67/300\n",
      " - 4s - loss: 1.3738 - acc: 0.4985 - val_loss: 1.3548 - val_acc: 0.5059\n",
      "Epoch 68/300\n",
      " - 4s - loss: 1.3714 - acc: 0.4989 - val_loss: 1.3540 - val_acc: 0.4964\n",
      "Epoch 69/300\n",
      " - 4s - loss: 1.3707 - acc: 0.5009 - val_loss: 1.3515 - val_acc: 0.4939\n",
      "Epoch 70/300\n",
      " - 4s - loss: 1.3685 - acc: 0.5026 - val_loss: 1.3461 - val_acc: 0.4964\n",
      "Epoch 71/300\n",
      " - 4s - loss: 1.3678 - acc: 0.5002 - val_loss: 1.3551 - val_acc: 0.4927\n",
      "Epoch 72/300\n",
      " - 4s - loss: 1.3684 - acc: 0.5007 - val_loss: 1.3438 - val_acc: 0.5063\n",
      "Epoch 73/300\n",
      " - 4s - loss: 1.3656 - acc: 0.5048 - val_loss: 1.3434 - val_acc: 0.4968\n",
      "Epoch 74/300\n",
      " - 4s - loss: 1.3645 - acc: 0.5038 - val_loss: 1.3443 - val_acc: 0.5030\n",
      "Epoch 75/300\n",
      " - 4s - loss: 1.3634 - acc: 0.5055 - val_loss: 1.3491 - val_acc: 0.5094\n",
      "Epoch 76/300\n",
      " - 4s - loss: 1.3637 - acc: 0.5071 - val_loss: 1.3449 - val_acc: 0.4968\n",
      "Epoch 77/300\n",
      " - 4s - loss: 1.3644 - acc: 0.5061 - val_loss: 1.3452 - val_acc: 0.5063\n",
      "Epoch 78/300\n",
      " - 4s - loss: 1.3622 - acc: 0.5090 - val_loss: 1.3437 - val_acc: 0.5092\n",
      "Epoch 79/300\n",
      " - 4s - loss: 1.3600 - acc: 0.5089 - val_loss: 1.3423 - val_acc: 0.5113\n",
      "Epoch 80/300\n",
      " - 4s - loss: 1.3613 - acc: 0.5084 - val_loss: 1.3466 - val_acc: 0.5193\n",
      "Epoch 81/300\n",
      " - 4s - loss: 1.3571 - acc: 0.5125 - val_loss: 1.3406 - val_acc: 0.5082\n",
      "Epoch 82/300\n",
      " - 4s - loss: 1.3573 - acc: 0.5099 - val_loss: 1.3375 - val_acc: 0.5016\n",
      "Epoch 83/300\n",
      " - 4s - loss: 1.3573 - acc: 0.5134 - val_loss: 1.3387 - val_acc: 0.5011\n",
      "Epoch 84/300\n",
      " - 4s - loss: 1.3553 - acc: 0.5108 - val_loss: 1.3361 - val_acc: 0.5119\n",
      "Epoch 85/300\n",
      " - 4s - loss: 1.3548 - acc: 0.5137 - val_loss: 1.3461 - val_acc: 0.5016\n",
      "Epoch 86/300\n",
      " - 4s - loss: 1.3554 - acc: 0.5137 - val_loss: 1.3351 - val_acc: 0.5100\n",
      "Epoch 87/300\n",
      " - 4s - loss: 1.3522 - acc: 0.5152 - val_loss: 1.3269 - val_acc: 0.5082\n",
      "Epoch 88/300\n",
      " - 4s - loss: 1.3511 - acc: 0.5149 - val_loss: 1.3321 - val_acc: 0.5082\n",
      "Epoch 89/300\n",
      " - 4s - loss: 1.3543 - acc: 0.5152 - val_loss: 1.3280 - val_acc: 0.5166\n",
      "Epoch 90/300\n",
      " - 4s - loss: 1.3522 - acc: 0.5154 - val_loss: 1.3331 - val_acc: 0.5158\n",
      "Epoch 91/300\n",
      " - 4s - loss: 1.3494 - acc: 0.5169 - val_loss: 1.3344 - val_acc: 0.5098\n",
      "Epoch 92/300\n",
      " - 4s - loss: 1.3504 - acc: 0.5203 - val_loss: 1.3371 - val_acc: 0.5084\n",
      "Epoch 93/300\n",
      " - 4s - loss: 1.3496 - acc: 0.5181 - val_loss: 1.3219 - val_acc: 0.5189\n",
      "Epoch 94/300\n",
      " - 4s - loss: 1.3477 - acc: 0.5192 - val_loss: 1.3229 - val_acc: 0.5162\n",
      "Epoch 95/300\n",
      " - 4s - loss: 1.3477 - acc: 0.5208 - val_loss: 1.3224 - val_acc: 0.5175\n",
      "Epoch 96/300\n",
      " - 4s - loss: 1.3469 - acc: 0.5205 - val_loss: 1.3239 - val_acc: 0.5263\n",
      "Epoch 97/300\n",
      " - 4s - loss: 1.3476 - acc: 0.5173 - val_loss: 1.3250 - val_acc: 0.5057\n",
      "Epoch 98/300\n",
      " - 4s - loss: 1.3459 - acc: 0.5194 - val_loss: 1.3228 - val_acc: 0.5193\n",
      "Epoch 99/300\n",
      " - 4s - loss: 1.3448 - acc: 0.5211 - val_loss: 1.3179 - val_acc: 0.5193\n",
      "Epoch 100/300\n",
      " - 4s - loss: 1.3435 - acc: 0.5204 - val_loss: 1.3210 - val_acc: 0.5168\n",
      "Epoch 101/300\n",
      " - 4s - loss: 1.3427 - acc: 0.5248 - val_loss: 1.3279 - val_acc: 0.5203\n",
      "Epoch 102/300\n",
      " - 4s - loss: 1.3418 - acc: 0.5232 - val_loss: 1.3207 - val_acc: 0.5238\n",
      "Epoch 103/300\n",
      " - 4s - loss: 1.3403 - acc: 0.5242 - val_loss: 1.3199 - val_acc: 0.5216\n",
      "Epoch 104/300\n",
      " - 4s - loss: 1.3411 - acc: 0.5259 - val_loss: 1.3196 - val_acc: 0.5224\n",
      "Epoch 105/300\n",
      " - 4s - loss: 1.3411 - acc: 0.5241 - val_loss: 1.3144 - val_acc: 0.5236\n",
      "Epoch 106/300\n",
      " - 4s - loss: 1.3384 - acc: 0.5258 - val_loss: 1.3163 - val_acc: 0.5296\n",
      "Epoch 107/300\n",
      " - 4s - loss: 1.3407 - acc: 0.5220 - val_loss: 1.3171 - val_acc: 0.5210\n",
      "Epoch 108/300\n",
      " - 4s - loss: 1.3368 - acc: 0.5244 - val_loss: 1.3143 - val_acc: 0.5220\n",
      "Epoch 109/300\n",
      " - 4s - loss: 1.3375 - acc: 0.5277 - val_loss: 1.3148 - val_acc: 0.5232\n",
      "Epoch 110/300\n",
      " - 4s - loss: 1.3364 - acc: 0.5272 - val_loss: 1.3188 - val_acc: 0.5216\n",
      "Epoch 111/300\n",
      " - 4s - loss: 1.3388 - acc: 0.5262 - val_loss: 1.3093 - val_acc: 0.5251\n",
      "Epoch 112/300\n",
      " - 4s - loss: 1.3357 - acc: 0.5295 - val_loss: 1.3135 - val_acc: 0.5164\n",
      "Epoch 113/300\n",
      " - 4s - loss: 1.3350 - acc: 0.5262 - val_loss: 1.3253 - val_acc: 0.5290\n",
      "Epoch 114/300\n",
      " - 4s - loss: 1.3364 - acc: 0.5276 - val_loss: 1.3140 - val_acc: 0.5294\n",
      "Epoch 115/300\n",
      " - 4s - loss: 1.3347 - acc: 0.5254 - val_loss: 1.3093 - val_acc: 0.5313\n",
      "Epoch 116/300\n",
      " - 4s - loss: 1.3362 - acc: 0.5259 - val_loss: 1.3095 - val_acc: 0.5267\n",
      "Epoch 117/300\n",
      " - 4s - loss: 1.3344 - acc: 0.5280 - val_loss: 1.3086 - val_acc: 0.5354\n",
      "Epoch 118/300\n",
      " - 4s - loss: 1.3337 - acc: 0.5285 - val_loss: 1.3235 - val_acc: 0.5220\n",
      "Epoch 119/300\n",
      " - 4s - loss: 1.3334 - acc: 0.5289 - val_loss: 1.3073 - val_acc: 0.5300\n",
      "Epoch 120/300\n",
      " - 4s - loss: 1.3333 - acc: 0.5299 - val_loss: 1.3054 - val_acc: 0.5300\n",
      "Epoch 121/300\n",
      " - 4s - loss: 1.3320 - acc: 0.5296 - val_loss: 1.3132 - val_acc: 0.5352\n",
      "Epoch 122/300\n",
      " - 4s - loss: 1.3332 - acc: 0.5291 - val_loss: 1.3135 - val_acc: 0.5239\n",
      "Epoch 123/300\n",
      " - 4s - loss: 1.3323 - acc: 0.5288 - val_loss: 1.3024 - val_acc: 0.5356\n",
      "Epoch 124/300\n",
      " - 4s - loss: 1.3342 - acc: 0.5287 - val_loss: 1.3034 - val_acc: 0.5302\n",
      "Epoch 125/300\n",
      " - 4s - loss: 1.3292 - acc: 0.5306 - val_loss: 1.3024 - val_acc: 0.5331\n",
      "Epoch 126/300\n",
      " - 4s - loss: 1.3322 - acc: 0.5313 - val_loss: 1.3034 - val_acc: 0.5360\n",
      "Epoch 127/300\n",
      " - 4s - loss: 1.3281 - acc: 0.5291 - val_loss: 1.3019 - val_acc: 0.5327\n",
      "Epoch 128/300\n",
      " - 4s - loss: 1.3304 - acc: 0.5297 - val_loss: 1.2995 - val_acc: 0.5344\n",
      "Epoch 129/300\n",
      " - 4s - loss: 1.3290 - acc: 0.5300 - val_loss: 1.3005 - val_acc: 0.5366\n",
      "Epoch 130/300\n",
      " - 4s - loss: 1.3312 - acc: 0.5310 - val_loss: 1.3017 - val_acc: 0.5282\n",
      "Epoch 131/300\n",
      " - 4s - loss: 1.3281 - acc: 0.5323 - val_loss: 1.3019 - val_acc: 0.5327\n",
      "Epoch 132/300\n",
      " - 4s - loss: 1.3306 - acc: 0.5300 - val_loss: 1.2983 - val_acc: 0.5329\n",
      "Epoch 133/300\n",
      " - 4s - loss: 1.3280 - acc: 0.5331 - val_loss: 1.3014 - val_acc: 0.5346\n",
      "Epoch 134/300\n",
      " - 4s - loss: 1.3277 - acc: 0.5306 - val_loss: 1.3037 - val_acc: 0.5391\n",
      "Epoch 135/300\n",
      " - 4s - loss: 1.3270 - acc: 0.5305 - val_loss: 1.2984 - val_acc: 0.5366\n",
      "Epoch 136/300\n",
      " - 4s - loss: 1.3267 - acc: 0.5354 - val_loss: 1.3013 - val_acc: 0.5334\n",
      "Epoch 137/300\n",
      " - 4s - loss: 1.3250 - acc: 0.5320 - val_loss: 1.3122 - val_acc: 0.5311\n",
      "Epoch 138/300\n",
      " - 4s - loss: 1.3243 - acc: 0.5311 - val_loss: 1.3003 - val_acc: 0.5284\n",
      "Epoch 139/300\n",
      " - 4s - loss: 1.3232 - acc: 0.5353 - val_loss: 1.2984 - val_acc: 0.5420\n",
      "Epoch 140/300\n",
      " - 4s - loss: 1.3261 - acc: 0.5321 - val_loss: 1.2949 - val_acc: 0.5406\n",
      "Epoch 141/300\n",
      " - 4s - loss: 1.3234 - acc: 0.5326 - val_loss: 1.2986 - val_acc: 0.5387\n",
      "Epoch 142/300\n",
      " - 4s - loss: 1.3242 - acc: 0.5341 - val_loss: 1.2902 - val_acc: 0.5344\n",
      "Epoch 143/300\n",
      " - 4s - loss: 1.3197 - acc: 0.5369 - val_loss: 1.2913 - val_acc: 0.5393\n",
      "Epoch 144/300\n",
      " - 4s - loss: 1.3229 - acc: 0.5352 - val_loss: 1.2962 - val_acc: 0.5342\n",
      "Epoch 145/300\n",
      " - 4s - loss: 1.3193 - acc: 0.5377 - val_loss: 1.2955 - val_acc: 0.5375\n",
      "Epoch 146/300\n",
      " - 4s - loss: 1.3208 - acc: 0.5359 - val_loss: 1.2930 - val_acc: 0.5389\n",
      "Epoch 147/300\n",
      " - 4s - loss: 1.3192 - acc: 0.5353 - val_loss: 1.2975 - val_acc: 0.5377\n",
      "Epoch 148/300\n",
      " - 4s - loss: 1.3205 - acc: 0.5357 - val_loss: 1.2954 - val_acc: 0.5329\n",
      "Epoch 149/300\n",
      " - 4s - loss: 1.3186 - acc: 0.5351 - val_loss: 1.2901 - val_acc: 0.5391\n",
      "Epoch 150/300\n",
      " - 4s - loss: 1.3178 - acc: 0.5364 - val_loss: 1.2965 - val_acc: 0.5364\n",
      "Epoch 151/300\n",
      " - 4s - loss: 1.3208 - acc: 0.5355 - val_loss: 1.2891 - val_acc: 0.5418\n",
      "Epoch 152/300\n",
      " - 4s - loss: 1.3194 - acc: 0.5376 - val_loss: 1.2910 - val_acc: 0.5472\n",
      "Epoch 153/300\n",
      " - 4s - loss: 1.3191 - acc: 0.5346 - val_loss: 1.2863 - val_acc: 0.5437\n",
      "Epoch 154/300\n",
      " - 4s - loss: 1.3166 - acc: 0.5350 - val_loss: 1.2848 - val_acc: 0.5391\n",
      "Epoch 155/300\n",
      " - 4s - loss: 1.3158 - acc: 0.5398 - val_loss: 1.2849 - val_acc: 0.5406\n",
      "Epoch 156/300\n",
      " - 4s - loss: 1.3165 - acc: 0.5385 - val_loss: 1.2859 - val_acc: 0.5410\n",
      "Epoch 157/300\n",
      " - 4s - loss: 1.3177 - acc: 0.5347 - val_loss: 1.2895 - val_acc: 0.5445\n",
      "Epoch 158/300\n",
      " - 4s - loss: 1.3170 - acc: 0.5390 - val_loss: 1.2882 - val_acc: 0.5447\n",
      "Epoch 159/300\n",
      " - 4s - loss: 1.3167 - acc: 0.5407 - val_loss: 1.2824 - val_acc: 0.5439\n",
      "Epoch 160/300\n",
      " - 4s - loss: 1.3166 - acc: 0.5378 - val_loss: 1.2901 - val_acc: 0.5548\n",
      "Epoch 161/300\n",
      " - 4s - loss: 1.3164 - acc: 0.5370 - val_loss: 1.2858 - val_acc: 0.5443\n",
      "Epoch 162/300\n",
      " - 4s - loss: 1.3148 - acc: 0.5404 - val_loss: 1.2961 - val_acc: 0.5362\n",
      "Epoch 163/300\n",
      " - 4s - loss: 1.3115 - acc: 0.5374 - val_loss: 1.2862 - val_acc: 0.5499\n",
      "Epoch 164/300\n",
      " - 4s - loss: 1.3141 - acc: 0.5397 - val_loss: 1.2869 - val_acc: 0.5377\n",
      "Epoch 165/300\n",
      " - 4s - loss: 1.3146 - acc: 0.5391 - val_loss: 1.2858 - val_acc: 0.5348\n",
      "Epoch 166/300\n",
      " - 4s - loss: 1.3147 - acc: 0.5402 - val_loss: 1.2942 - val_acc: 0.5325\n",
      "Epoch 167/300\n",
      " - 4s - loss: 1.3124 - acc: 0.5426 - val_loss: 1.2887 - val_acc: 0.5433\n",
      "Epoch 168/300\n",
      " - 4s - loss: 1.3123 - acc: 0.5420 - val_loss: 1.2797 - val_acc: 0.5505\n",
      "Epoch 169/300\n",
      " - 4s - loss: 1.3123 - acc: 0.5410 - val_loss: 1.2871 - val_acc: 0.5472\n",
      "Epoch 170/300\n",
      " - 4s - loss: 1.3112 - acc: 0.5432 - val_loss: 1.2832 - val_acc: 0.5478\n",
      "Epoch 171/300\n",
      " - 4s - loss: 1.3110 - acc: 0.5401 - val_loss: 1.2843 - val_acc: 0.5389\n",
      "Epoch 172/300\n",
      " - 4s - loss: 1.3095 - acc: 0.5410 - val_loss: 1.2824 - val_acc: 0.5441\n",
      "Epoch 173/300\n",
      " - 4s - loss: 1.3141 - acc: 0.5387 - val_loss: 1.2807 - val_acc: 0.5420\n",
      "Epoch 174/300\n",
      " - 4s - loss: 1.3080 - acc: 0.5444 - val_loss: 1.2909 - val_acc: 0.5466\n",
      "Epoch 175/300\n",
      " - 4s - loss: 1.3085 - acc: 0.5440 - val_loss: 1.2751 - val_acc: 0.5492\n",
      "Epoch 176/300\n",
      " - 4s - loss: 1.3121 - acc: 0.5409 - val_loss: 1.2822 - val_acc: 0.5515\n",
      "Epoch 177/300\n",
      " - 4s - loss: 1.3096 - acc: 0.5415 - val_loss: 1.2781 - val_acc: 0.5503\n",
      "Epoch 178/300\n",
      " - 4s - loss: 1.3092 - acc: 0.5452 - val_loss: 1.2771 - val_acc: 0.5517\n",
      "Epoch 179/300\n",
      " - 4s - loss: 1.3101 - acc: 0.5437 - val_loss: 1.2700 - val_acc: 0.5501\n",
      "Epoch 180/300\n",
      " - 4s - loss: 1.3069 - acc: 0.5463 - val_loss: 1.2727 - val_acc: 0.5468\n",
      "Epoch 181/300\n",
      " - 4s - loss: 1.3052 - acc: 0.5450 - val_loss: 1.2835 - val_acc: 0.5538\n",
      "Epoch 182/300\n",
      " - 4s - loss: 1.3044 - acc: 0.5465 - val_loss: 1.2746 - val_acc: 0.5466\n",
      "Epoch 183/300\n",
      " - 4s - loss: 1.3067 - acc: 0.5444 - val_loss: 1.2851 - val_acc: 0.5482\n",
      "Epoch 184/300\n",
      " - 4s - loss: 1.3045 - acc: 0.5444 - val_loss: 1.2852 - val_acc: 0.5480\n",
      "Epoch 185/300\n",
      " - 4s - loss: 1.3077 - acc: 0.5429 - val_loss: 1.2735 - val_acc: 0.5542\n",
      "Epoch 186/300\n",
      " - 4s - loss: 1.3044 - acc: 0.5448 - val_loss: 1.2784 - val_acc: 0.5484\n",
      "Epoch 187/300\n",
      " - 4s - loss: 1.3067 - acc: 0.5421 - val_loss: 1.2721 - val_acc: 0.5509\n",
      "Epoch 188/300\n",
      " - 4s - loss: 1.3039 - acc: 0.5442 - val_loss: 1.2735 - val_acc: 0.5589\n",
      "Epoch 189/300\n",
      " - 4s - loss: 1.3033 - acc: 0.5436 - val_loss: 1.2680 - val_acc: 0.5513\n",
      "Epoch 190/300\n",
      " - 4s - loss: 1.3029 - acc: 0.5440 - val_loss: 1.2800 - val_acc: 0.5422\n",
      "Epoch 191/300\n",
      " - 4s - loss: 1.3031 - acc: 0.5459 - val_loss: 1.2662 - val_acc: 0.5466\n",
      "Epoch 192/300\n",
      " - 4s - loss: 1.3033 - acc: 0.5464 - val_loss: 1.2702 - val_acc: 0.5445\n",
      "Epoch 193/300\n",
      " - 4s - loss: 1.3032 - acc: 0.5465 - val_loss: 1.2695 - val_acc: 0.5532\n",
      "Epoch 194/300\n",
      " - 4s - loss: 1.3004 - acc: 0.5477 - val_loss: 1.2686 - val_acc: 0.5528\n",
      "Epoch 195/300\n",
      " - 4s - loss: 1.3040 - acc: 0.5453 - val_loss: 1.2689 - val_acc: 0.5575\n",
      "Epoch 196/300\n",
      " - 4s - loss: 1.3015 - acc: 0.5471 - val_loss: 1.2826 - val_acc: 0.5451\n",
      "Epoch 197/300\n",
      " - 4s - loss: 1.3045 - acc: 0.5452 - val_loss: 1.2701 - val_acc: 0.5557\n",
      "Epoch 198/300\n",
      " - 4s - loss: 1.2966 - acc: 0.5465 - val_loss: 1.2755 - val_acc: 0.5596\n",
      "Epoch 199/300\n",
      " - 4s - loss: 1.2991 - acc: 0.5479 - val_loss: 1.2662 - val_acc: 0.5548\n",
      "Epoch 200/300\n",
      " - 4s - loss: 1.2976 - acc: 0.5485 - val_loss: 1.2649 - val_acc: 0.5633\n",
      "Epoch 201/300\n",
      " - 4s - loss: 1.2975 - acc: 0.5503 - val_loss: 1.2676 - val_acc: 0.5536\n",
      "Epoch 202/300\n",
      " - 4s - loss: 1.2981 - acc: 0.5450 - val_loss: 1.2621 - val_acc: 0.5604\n",
      "Epoch 203/300\n",
      " - 4s - loss: 1.2958 - acc: 0.5493 - val_loss: 1.2680 - val_acc: 0.5497\n",
      "Epoch 204/300\n",
      " - 4s - loss: 1.3007 - acc: 0.5467 - val_loss: 1.2667 - val_acc: 0.5455\n",
      "Epoch 205/300\n",
      " - 4s - loss: 1.3017 - acc: 0.5450 - val_loss: 1.2579 - val_acc: 0.5542\n",
      "Epoch 206/300\n",
      " - 4s - loss: 1.2934 - acc: 0.5500 - val_loss: 1.2801 - val_acc: 0.5507\n",
      "Epoch 207/300\n",
      " - 4s - loss: 1.2998 - acc: 0.5481 - val_loss: 1.2575 - val_acc: 0.5625\n",
      "Epoch 208/300\n",
      " - 4s - loss: 1.2951 - acc: 0.5495 - val_loss: 1.2670 - val_acc: 0.5618\n",
      "Epoch 209/300\n",
      " - 4s - loss: 1.2962 - acc: 0.5476 - val_loss: 1.2647 - val_acc: 0.5600\n",
      "Epoch 210/300\n",
      " - 4s - loss: 1.2961 - acc: 0.5477 - val_loss: 1.2740 - val_acc: 0.5410\n",
      "Epoch 211/300\n",
      " - 4s - loss: 1.2959 - acc: 0.5470 - val_loss: 1.2677 - val_acc: 0.5559\n",
      "Epoch 212/300\n",
      " - 4s - loss: 1.2941 - acc: 0.5512 - val_loss: 1.2602 - val_acc: 0.5548\n",
      "Epoch 213/300\n",
      " - 4s - loss: 1.2961 - acc: 0.5482 - val_loss: 1.2634 - val_acc: 0.5554\n",
      "Epoch 214/300\n",
      " - 4s - loss: 1.2954 - acc: 0.5489 - val_loss: 1.2570 - val_acc: 0.5577\n",
      "Epoch 215/300\n",
      " - 4s - loss: 1.2959 - acc: 0.5504 - val_loss: 1.2579 - val_acc: 0.5598\n",
      "Epoch 216/300\n",
      " - 4s - loss: 1.2961 - acc: 0.5502 - val_loss: 1.2608 - val_acc: 0.5602\n",
      "Epoch 217/300\n",
      " - 4s - loss: 1.2973 - acc: 0.5483 - val_loss: 1.2601 - val_acc: 0.5554\n",
      "Epoch 218/300\n",
      " - 4s - loss: 1.2936 - acc: 0.5470 - val_loss: 1.2635 - val_acc: 0.5610\n",
      "Epoch 219/300\n",
      " - 4s - loss: 1.2933 - acc: 0.5487 - val_loss: 1.2645 - val_acc: 0.5573\n",
      "Epoch 220/300\n",
      " - 4s - loss: 1.2942 - acc: 0.5500 - val_loss: 1.2596 - val_acc: 0.5559\n",
      "Epoch 221/300\n",
      " - 4s - loss: 1.2960 - acc: 0.5476 - val_loss: 1.2600 - val_acc: 0.5635\n",
      "Epoch 222/300\n",
      " - 4s - loss: 1.2922 - acc: 0.5493 - val_loss: 1.2689 - val_acc: 0.5649\n",
      "Epoch 223/300\n",
      " - 4s - loss: 1.2885 - acc: 0.5528 - val_loss: 1.2558 - val_acc: 0.5658\n",
      "Epoch 224/300\n",
      " - 4s - loss: 1.2914 - acc: 0.5488 - val_loss: 1.2620 - val_acc: 0.5540\n",
      "Epoch 225/300\n",
      " - 4s - loss: 1.2915 - acc: 0.5504 - val_loss: 1.2578 - val_acc: 0.5616\n",
      "Epoch 226/300\n",
      " - 4s - loss: 1.2927 - acc: 0.5484 - val_loss: 1.2598 - val_acc: 0.5509\n",
      "Epoch 227/300\n",
      " - 4s - loss: 1.2935 - acc: 0.5498 - val_loss: 1.2675 - val_acc: 0.5563\n",
      "Epoch 228/300\n",
      " - 4s - loss: 1.2918 - acc: 0.5479 - val_loss: 1.2594 - val_acc: 0.5546\n",
      "Epoch 229/300\n",
      " - 4s - loss: 1.2924 - acc: 0.5492 - val_loss: 1.2581 - val_acc: 0.5604\n",
      "Epoch 230/300\n",
      " - 4s - loss: 1.2913 - acc: 0.5505 - val_loss: 1.2494 - val_acc: 0.5635\n",
      "Epoch 231/300\n",
      " - 4s - loss: 1.2925 - acc: 0.5511 - val_loss: 1.2668 - val_acc: 0.5594\n",
      "Epoch 232/300\n",
      " - 4s - loss: 1.2914 - acc: 0.5501 - val_loss: 1.2601 - val_acc: 0.5625\n",
      "Epoch 233/300\n",
      " - 4s - loss: 1.2895 - acc: 0.5507 - val_loss: 1.2638 - val_acc: 0.5484\n",
      "Epoch 234/300\n",
      " - 4s - loss: 1.2888 - acc: 0.5499 - val_loss: 1.2620 - val_acc: 0.5653\n",
      "Epoch 235/300\n",
      " - 4s - loss: 1.2888 - acc: 0.5495 - val_loss: 1.2761 - val_acc: 0.5398\n",
      "Epoch 236/300\n",
      " - 4s - loss: 1.2846 - acc: 0.5514 - val_loss: 1.2504 - val_acc: 0.5621\n",
      "Epoch 237/300\n",
      " - 4s - loss: 1.2928 - acc: 0.5495 - val_loss: 1.2578 - val_acc: 0.5633\n",
      "Epoch 238/300\n",
      " - 4s - loss: 1.2847 - acc: 0.5531 - val_loss: 1.2831 - val_acc: 0.5464\n",
      "Epoch 239/300\n",
      " - 4s - loss: 1.2866 - acc: 0.5530 - val_loss: 1.2438 - val_acc: 0.5658\n",
      "Epoch 240/300\n",
      " - 4s - loss: 1.2887 - acc: 0.5514 - val_loss: 1.2479 - val_acc: 0.5685\n",
      "Epoch 241/300\n",
      " - 4s - loss: 1.2877 - acc: 0.5541 - val_loss: 1.2597 - val_acc: 0.5629\n",
      "Epoch 242/300\n",
      " - 4s - loss: 1.2902 - acc: 0.5510 - val_loss: 1.2527 - val_acc: 0.5678\n",
      "Epoch 243/300\n",
      " - 4s - loss: 1.2843 - acc: 0.5540 - val_loss: 1.2483 - val_acc: 0.5662\n",
      "Epoch 244/300\n",
      " - 4s - loss: 1.2856 - acc: 0.5535 - val_loss: 1.2547 - val_acc: 0.5517\n",
      "Epoch 245/300\n",
      " - 4s - loss: 1.2875 - acc: 0.5518 - val_loss: 1.2499 - val_acc: 0.5629\n",
      "Epoch 246/300\n",
      " - 4s - loss: 1.2834 - acc: 0.5524 - val_loss: 1.2578 - val_acc: 0.5561\n",
      "Epoch 247/300\n",
      " - 4s - loss: 1.2858 - acc: 0.5547 - val_loss: 1.2551 - val_acc: 0.5590\n",
      "Epoch 248/300\n",
      " - 4s - loss: 1.2893 - acc: 0.5476 - val_loss: 1.2461 - val_acc: 0.5678\n",
      "Epoch 249/300\n",
      " - 4s - loss: 1.2866 - acc: 0.5484 - val_loss: 1.2608 - val_acc: 0.5596\n",
      "Epoch 250/300\n",
      " - 4s - loss: 1.2835 - acc: 0.5526 - val_loss: 1.2521 - val_acc: 0.5654\n",
      "Epoch 251/300\n",
      " - 4s - loss: 1.2860 - acc: 0.5534 - val_loss: 1.2550 - val_acc: 0.5565\n",
      "Epoch 252/300\n",
      " - 4s - loss: 1.2874 - acc: 0.5529 - val_loss: 1.2477 - val_acc: 0.5670\n",
      "Epoch 253/300\n",
      " - 4s - loss: 1.2841 - acc: 0.5553 - val_loss: 1.2484 - val_acc: 0.5614\n",
      "Epoch 254/300\n",
      " - 4s - loss: 1.2833 - acc: 0.5546 - val_loss: 1.2439 - val_acc: 0.5672\n",
      "Epoch 255/300\n",
      " - 4s - loss: 1.2859 - acc: 0.5530 - val_loss: 1.2501 - val_acc: 0.5620\n",
      "Epoch 256/300\n",
      " - 4s - loss: 1.2832 - acc: 0.5510 - val_loss: 1.2529 - val_acc: 0.5590\n",
      "Epoch 257/300\n",
      " - 4s - loss: 1.2849 - acc: 0.5532 - val_loss: 1.2461 - val_acc: 0.5653\n",
      "Epoch 258/300\n",
      " - 4s - loss: 1.2815 - acc: 0.5568 - val_loss: 1.2462 - val_acc: 0.5759\n",
      "Epoch 259/300\n",
      " - 4s - loss: 1.2840 - acc: 0.5554 - val_loss: 1.2511 - val_acc: 0.5670\n",
      "Epoch 260/300\n",
      " - 4s - loss: 1.2852 - acc: 0.5541 - val_loss: 1.2476 - val_acc: 0.5672\n",
      "Epoch 261/300\n",
      " - 4s - loss: 1.2837 - acc: 0.5556 - val_loss: 1.2475 - val_acc: 0.5637\n",
      "Epoch 262/300\n",
      " - 4s - loss: 1.2825 - acc: 0.5538 - val_loss: 1.2577 - val_acc: 0.5587\n",
      "Epoch 263/300\n",
      " - 4s - loss: 1.2821 - acc: 0.5572 - val_loss: 1.2439 - val_acc: 0.5722\n",
      "Epoch 264/300\n",
      " - 4s - loss: 1.2862 - acc: 0.5547 - val_loss: 1.2535 - val_acc: 0.5606\n",
      "Epoch 265/300\n",
      " - 4s - loss: 1.2831 - acc: 0.5543 - val_loss: 1.2453 - val_acc: 0.5680\n",
      "Epoch 266/300\n",
      " - 4s - loss: 1.2850 - acc: 0.5507 - val_loss: 1.2474 - val_acc: 0.5594\n",
      "Epoch 267/300\n",
      " - 4s - loss: 1.2810 - acc: 0.5564 - val_loss: 1.2349 - val_acc: 0.5790\n",
      "Epoch 268/300\n",
      " - 4s - loss: 1.2801 - acc: 0.5577 - val_loss: 1.2488 - val_acc: 0.5612\n",
      "Epoch 269/300\n",
      " - 4s - loss: 1.2822 - acc: 0.5553 - val_loss: 1.2436 - val_acc: 0.5722\n",
      "Epoch 270/300\n",
      " - 4s - loss: 1.2805 - acc: 0.5571 - val_loss: 1.2435 - val_acc: 0.5616\n",
      "Epoch 271/300\n",
      " - 4s - loss: 1.2828 - acc: 0.5554 - val_loss: 1.2556 - val_acc: 0.5530\n",
      "Epoch 272/300\n",
      " - 4s - loss: 1.2803 - acc: 0.5536 - val_loss: 1.2455 - val_acc: 0.5656\n",
      "Epoch 273/300\n",
      " - 4s - loss: 1.2817 - acc: 0.5539 - val_loss: 1.2464 - val_acc: 0.5643\n",
      "Epoch 274/300\n",
      " - 4s - loss: 1.2786 - acc: 0.5596 - val_loss: 1.2484 - val_acc: 0.5596\n",
      "Epoch 275/300\n",
      " - 4s - loss: 1.2789 - acc: 0.5554 - val_loss: 1.2415 - val_acc: 0.5674\n",
      "Epoch 276/300\n",
      " - 4s - loss: 1.2798 - acc: 0.5572 - val_loss: 1.2493 - val_acc: 0.5654\n",
      "Epoch 277/300\n",
      " - 4s - loss: 1.2810 - acc: 0.5553 - val_loss: 1.2539 - val_acc: 0.5600\n",
      "Epoch 278/300\n",
      " - 4s - loss: 1.2840 - acc: 0.5519 - val_loss: 1.2463 - val_acc: 0.5697\n",
      "Epoch 279/300\n",
      " - 4s - loss: 1.2804 - acc: 0.5561 - val_loss: 1.2416 - val_acc: 0.5771\n",
      "Epoch 280/300\n",
      " - 4s - loss: 1.2798 - acc: 0.5535 - val_loss: 1.2364 - val_acc: 0.5726\n",
      "Epoch 281/300\n",
      " - 4s - loss: 1.2769 - acc: 0.5545 - val_loss: 1.2426 - val_acc: 0.5693\n",
      "Epoch 282/300\n",
      " - 4s - loss: 1.2808 - acc: 0.5559 - val_loss: 1.2477 - val_acc: 0.5600\n",
      "Epoch 283/300\n",
      " - 4s - loss: 1.2785 - acc: 0.5549 - val_loss: 1.2426 - val_acc: 0.5684\n",
      "Epoch 284/300\n",
      " - 4s - loss: 1.2776 - acc: 0.5595 - val_loss: 1.2429 - val_acc: 0.5604\n",
      "Epoch 285/300\n",
      " - 4s - loss: 1.2784 - acc: 0.5562 - val_loss: 1.2412 - val_acc: 0.5645\n",
      "Epoch 286/300\n",
      " - 4s - loss: 1.2814 - acc: 0.5549 - val_loss: 1.2348 - val_acc: 0.5709\n",
      "Epoch 287/300\n",
      " - 4s - loss: 1.2779 - acc: 0.5589 - val_loss: 1.2466 - val_acc: 0.5610\n",
      "Epoch 288/300\n",
      " - 4s - loss: 1.2785 - acc: 0.5549 - val_loss: 1.2486 - val_acc: 0.5596\n",
      "Epoch 289/300\n",
      " - 4s - loss: 1.2774 - acc: 0.5582 - val_loss: 1.2442 - val_acc: 0.5654\n",
      "Epoch 290/300\n",
      " - 4s - loss: 1.2814 - acc: 0.5557 - val_loss: 1.2473 - val_acc: 0.5703\n",
      "Epoch 291/300\n",
      " - 4s - loss: 1.2770 - acc: 0.5594 - val_loss: 1.2394 - val_acc: 0.5718\n",
      "Epoch 292/300\n",
      " - 4s - loss: 1.2756 - acc: 0.5557 - val_loss: 1.2379 - val_acc: 0.5711\n",
      "Epoch 293/300\n",
      " - 4s - loss: 1.2755 - acc: 0.5538 - val_loss: 1.2447 - val_acc: 0.5691\n",
      "Epoch 294/300\n",
      " - 4s - loss: 1.2745 - acc: 0.5610 - val_loss: 1.2486 - val_acc: 0.5674\n",
      "Epoch 295/300\n",
      " - 4s - loss: 1.2775 - acc: 0.5571 - val_loss: 1.2390 - val_acc: 0.5670\n",
      "Epoch 296/300\n",
      " - 4s - loss: 1.2747 - acc: 0.5599 - val_loss: 1.2341 - val_acc: 0.5782\n",
      "Epoch 297/300\n",
      " - 4s - loss: 1.2764 - acc: 0.5538 - val_loss: 1.2478 - val_acc: 0.5666\n",
      "Epoch 298/300\n",
      " - 4s - loss: 1.2751 - acc: 0.5567 - val_loss: 1.2374 - val_acc: 0.5691\n",
      "Epoch 299/300\n",
      " - 4s - loss: 1.2789 - acc: 0.5552 - val_loss: 1.2443 - val_acc: 0.5682\n",
      "Epoch 300/300\n",
      " - 4s - loss: 1.2778 - acc: 0.5569 - val_loss: 1.2480 - val_acc: 0.5581\n",
      "Final score (RMSE): 0.2874068689154143\n",
      "(20624, 7)\n",
      "(20624,)\n",
      "Accuracy train:  0.5687063615205585\n",
      "Final Test score (RMSE): 0.2895566087778286\n",
      "Accuracy test:  0.5580764010083382\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInitializing Keras\\n\")\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape = (input_shape,),  activation = 'relu', kernel_regularizer= regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(Dense(75, activation = 'relu',kernel_regularizer= regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(Dense(25, activation= 'relu', kernel_regularizer= regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(Dense(7,activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) # adaptive momentum solves issue of local minimum\n",
    "#model.summary()\n",
    "\n",
    "monitor = EarlyStopping(monitor='loss', min_delta= 1e-3, patience = 5, verbose = 1, mode = 'auto' )\n",
    "\n",
    "#model.fit(X_train, np.array(train_labels_one_hot),callbacks = [monitor], verbose = 2, epochs = 25)\n",
    "history = model.fit(X_train, np.array(train_labels_one_hot), batch_size= 32, validation_data= (x_val, y_val),verbose = 2, epochs = 300)\n",
    "#history = model.fit_generator(X_train, steps_per_epoch = 100, epochs = 10, validation_data = np.array(train_labels_one_hot), verbose = 2, validation_steps = 50)\n",
    "pred = model.predict(X_train)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,train_labels_one_hot))\n",
    "print(f\"Final score (RMSE): {score}\")\n",
    "\n",
    "print(pred.shape)\n",
    "print(y_train.shape)\n",
    "corrects,wrongs = 0,0\n",
    "for i in range(len(pred)):\n",
    "    res = pred[i]\n",
    "    res_max = res.argmax()\n",
    "    if res_max == y_train[i]:\n",
    "        corrects += 1\n",
    "    else:\n",
    "        wrongs += 1\n",
    "        \n",
    "print(\"Accuracy train: \", corrects / (corrects + wrongs))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,test_labels_one_hot))\n",
    "print(f\"Final Test score (RMSE): {score}\")\n",
    "\n",
    "corrects,wrongs = 0,0\n",
    "for i in range(len(pred)):\n",
    "    res = pred[i]\n",
    "    res_max = res.argmax()\n",
    "    if res_max == y_test[i]:\n",
    "        corrects += 1\n",
    "    else:\n",
    "        wrongs += 1\n",
    "        \n",
    "print(\"Accuracy test: \", corrects / (corrects + wrongs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "58C-TFs0Thys",
    "outputId": "3b73bf79-9b86-46d6-cd84-a5dbd7a60187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Keras\n",
      "\n",
      "Train on 20624 samples, validate on 5157 samples\n",
      "Epoch 1/300\n",
      " - 5s - loss: 8.4335 - acc: 0.4779 - val_loss: 8.3348 - val_acc: 0.4848\n",
      "Epoch 2/300\n",
      " - 4s - loss: 8.3880 - acc: 0.4810 - val_loss: 8.3399 - val_acc: 0.4848\n",
      "Epoch 3/300\n",
      " - 4s - loss: 8.3664 - acc: 0.4827 - val_loss: 8.3380 - val_acc: 0.4848\n",
      "Epoch 4/300\n",
      " - 4s - loss: 8.3656 - acc: 0.4828 - val_loss: 8.3362 - val_acc: 0.4848\n",
      "Epoch 5/300\n",
      " - 4s - loss: 8.3632 - acc: 0.4827 - val_loss: 8.3283 - val_acc: 0.4848\n",
      "Epoch 6/300\n",
      " - 4s - loss: 11.3858 - acc: 0.2948 - val_loss: 14.7566 - val_acc: 0.0861\n",
      "Epoch 7/300\n",
      " - 4s - loss: 14.8080 - acc: 0.0826 - val_loss: 14.7546 - val_acc: 0.0861\n",
      "Epoch 8/300\n",
      " - 4s - loss: 14.8061 - acc: 0.0827 - val_loss: 14.7526 - val_acc: 0.0861\n",
      "Epoch 9/300\n",
      " - 4s - loss: 14.8040 - acc: 0.0827 - val_loss: 14.7505 - val_acc: 0.0865\n",
      "Epoch 10/300\n",
      " - 4s - loss: 14.8019 - acc: 0.0830 - val_loss: 14.7483 - val_acc: 0.0865\n",
      "Epoch 11/300\n",
      " - 4s - loss: 14.7996 - acc: 0.0830 - val_loss: 14.7459 - val_acc: 0.0865\n",
      "Epoch 12/300\n",
      " - 4s - loss: 14.7972 - acc: 0.0829 - val_loss: 14.7434 - val_acc: 0.0865\n",
      "Epoch 13/300\n",
      " - 4s - loss: 14.7946 - acc: 0.0830 - val_loss: 14.7408 - val_acc: 0.0865\n",
      "Epoch 14/300\n",
      " - 4s - loss: 14.7920 - acc: 0.0830 - val_loss: 14.7382 - val_acc: 0.0865\n",
      "Epoch 15/300\n",
      " - 4s - loss: 14.7894 - acc: 0.0830 - val_loss: 14.7357 - val_acc: 0.0865\n",
      "Epoch 16/300\n",
      " - 4s - loss: 14.7870 - acc: 0.0829 - val_loss: 14.7334 - val_acc: 0.0865\n",
      "Epoch 17/300\n",
      " - 4s - loss: 14.7832 - acc: 0.0831 - val_loss: 14.7312 - val_acc: 0.0865\n",
      "Epoch 18/300\n",
      " - 4s - loss: 14.7793 - acc: 0.0825 - val_loss: 14.7074 - val_acc: 0.0865\n",
      "Epoch 19/300\n",
      " - 4s - loss: 13.7111 - acc: 0.1410 - val_loss: 7.7733 - val_acc: 0.4941\n",
      "Epoch 20/300\n",
      " - 4s - loss: 1.8018 - acc: 0.4352 - val_loss: 1.3884 - val_acc: 0.4970\n",
      "Epoch 21/300\n",
      " - 4s - loss: 1.3932 - acc: 0.4823 - val_loss: 1.3502 - val_acc: 0.5030\n",
      "Epoch 22/300\n",
      " - 4s - loss: 1.3591 - acc: 0.4848 - val_loss: 1.3266 - val_acc: 0.5049\n",
      "Epoch 23/300\n",
      " - 4s - loss: 1.3429 - acc: 0.4869 - val_loss: 1.3151 - val_acc: 0.5030\n",
      "Epoch 24/300\n",
      " - 4s - loss: 1.3315 - acc: 0.4872 - val_loss: 1.3096 - val_acc: 0.5028\n",
      "Epoch 25/300\n",
      " - 4s - loss: 1.3238 - acc: 0.4905 - val_loss: 1.3019 - val_acc: 0.5059\n",
      "Epoch 26/300\n",
      " - 4s - loss: 1.3172 - acc: 0.4950 - val_loss: 1.2988 - val_acc: 0.5063\n",
      "Epoch 27/300\n",
      " - 4s - loss: 1.3195 - acc: 0.4946 - val_loss: 1.2989 - val_acc: 0.5063\n",
      "Epoch 28/300\n",
      " - 4s - loss: 1.3124 - acc: 0.4910 - val_loss: 1.2922 - val_acc: 0.5063\n",
      "Epoch 29/300\n",
      " - 4s - loss: 1.3088 - acc: 0.4892 - val_loss: 1.2863 - val_acc: 0.5067\n",
      "Epoch 30/300\n",
      " - 4s - loss: 1.3069 - acc: 0.4882 - val_loss: 1.2845 - val_acc: 0.5063\n",
      "Epoch 31/300\n",
      " - 4s - loss: 1.2994 - acc: 0.4900 - val_loss: 1.2842 - val_acc: 0.5063\n",
      "Epoch 32/300\n",
      " - 4s - loss: 1.3012 - acc: 0.4856 - val_loss: 1.2789 - val_acc: 0.5063\n",
      "Epoch 33/300\n",
      " - 4s - loss: 1.2968 - acc: 0.4893 - val_loss: 1.2785 - val_acc: 0.5075\n",
      "Epoch 34/300\n",
      " - 4s - loss: 1.2963 - acc: 0.4890 - val_loss: 1.2742 - val_acc: 0.5065\n",
      "Epoch 35/300\n",
      " - 4s - loss: 1.2974 - acc: 0.4881 - val_loss: 1.2741 - val_acc: 0.5069\n",
      "Epoch 36/300\n",
      " - 4s - loss: 1.2948 - acc: 0.4909 - val_loss: 1.2766 - val_acc: 0.5061\n",
      "Epoch 37/300\n",
      " - 4s - loss: 1.2899 - acc: 0.5020 - val_loss: 1.2757 - val_acc: 0.5104\n",
      "Epoch 38/300\n",
      " - 4s - loss: 1.2883 - acc: 0.5025 - val_loss: 1.2663 - val_acc: 0.5071\n",
      "Epoch 39/300\n",
      " - 4s - loss: 1.2846 - acc: 0.5024 - val_loss: 1.2644 - val_acc: 0.5059\n",
      "Epoch 40/300\n",
      " - 4s - loss: 1.2850 - acc: 0.5009 - val_loss: 1.2665 - val_acc: 0.5063\n",
      "Epoch 41/300\n",
      " - 4s - loss: 1.2836 - acc: 0.5029 - val_loss: 1.2676 - val_acc: 0.5069\n",
      "Epoch 42/300\n",
      " - 4s - loss: 1.2818 - acc: 0.5032 - val_loss: 1.2649 - val_acc: 0.5071\n",
      "Epoch 43/300\n",
      " - 4s - loss: 1.2808 - acc: 0.5017 - val_loss: 1.2631 - val_acc: 0.5092\n",
      "Epoch 44/300\n",
      " - 4s - loss: 1.2813 - acc: 0.5044 - val_loss: 1.2733 - val_acc: 0.5094\n",
      "Epoch 45/300\n",
      " - 4s - loss: 1.2825 - acc: 0.5030 - val_loss: 1.2628 - val_acc: 0.5100\n",
      "Epoch 46/300\n",
      " - 4s - loss: 1.2796 - acc: 0.5034 - val_loss: 1.2735 - val_acc: 0.5032\n",
      "Epoch 47/300\n",
      " - 4s - loss: 1.2785 - acc: 0.5069 - val_loss: 1.2630 - val_acc: 0.5115\n",
      "Epoch 48/300\n",
      " - 4s - loss: 1.2791 - acc: 0.5067 - val_loss: 1.2610 - val_acc: 0.5129\n",
      "Epoch 49/300\n",
      " - 4s - loss: 1.2763 - acc: 0.5078 - val_loss: 1.2609 - val_acc: 0.5119\n",
      "Epoch 50/300\n",
      " - 4s - loss: 1.2779 - acc: 0.5064 - val_loss: 1.2605 - val_acc: 0.5096\n",
      "Epoch 51/300\n",
      " - 4s - loss: 1.2785 - acc: 0.5080 - val_loss: 1.2646 - val_acc: 0.5110\n",
      "Epoch 52/300\n",
      " - 4s - loss: 1.2783 - acc: 0.5084 - val_loss: 1.2705 - val_acc: 0.5063\n",
      "Epoch 53/300\n",
      " - 4s - loss: 1.2756 - acc: 0.5075 - val_loss: 1.2672 - val_acc: 0.5073\n",
      "Epoch 54/300\n",
      " - 4s - loss: 1.2762 - acc: 0.5080 - val_loss: 1.2601 - val_acc: 0.5108\n",
      "Epoch 55/300\n",
      " - 4s - loss: 1.2751 - acc: 0.5088 - val_loss: 1.2669 - val_acc: 0.5179\n",
      "Epoch 56/300\n",
      " - 4s - loss: 1.2736 - acc: 0.5071 - val_loss: 1.2604 - val_acc: 0.5139\n",
      "Epoch 57/300\n",
      " - 4s - loss: 1.2735 - acc: 0.5090 - val_loss: 1.2620 - val_acc: 0.5158\n",
      "Epoch 58/300\n",
      " - 4s - loss: 1.2744 - acc: 0.5069 - val_loss: 1.2636 - val_acc: 0.5172\n",
      "Epoch 59/300\n",
      " - 4s - loss: 1.2740 - acc: 0.5093 - val_loss: 1.2576 - val_acc: 0.5166\n",
      "Epoch 60/300\n",
      " - 4s - loss: 1.2736 - acc: 0.5075 - val_loss: 1.2593 - val_acc: 0.5125\n",
      "Epoch 61/300\n",
      " - 4s - loss: 1.2738 - acc: 0.5101 - val_loss: 1.2590 - val_acc: 0.5119\n",
      "Epoch 62/300\n",
      " - 4s - loss: 1.2712 - acc: 0.5084 - val_loss: 1.2601 - val_acc: 0.5158\n",
      "Epoch 63/300\n",
      " - 4s - loss: 1.2736 - acc: 0.5082 - val_loss: 1.2604 - val_acc: 0.5168\n",
      "Epoch 64/300\n",
      " - 4s - loss: 1.2732 - acc: 0.5082 - val_loss: 1.2659 - val_acc: 0.5079\n",
      "Epoch 65/300\n",
      " - 4s - loss: 1.2727 - acc: 0.5075 - val_loss: 1.2585 - val_acc: 0.5117\n",
      "Epoch 66/300\n",
      " - 4s - loss: 1.2731 - acc: 0.5089 - val_loss: 1.2593 - val_acc: 0.5121\n",
      "Epoch 67/300\n",
      " - 4s - loss: 1.2761 - acc: 0.5074 - val_loss: 1.2602 - val_acc: 0.5096\n",
      "Epoch 68/300\n",
      " - 4s - loss: 1.2721 - acc: 0.5076 - val_loss: 1.2577 - val_acc: 0.5150\n",
      "Epoch 69/300\n",
      " - 4s - loss: 1.2725 - acc: 0.5061 - val_loss: 1.2562 - val_acc: 0.5160\n",
      "Epoch 70/300\n",
      " - 4s - loss: 1.2707 - acc: 0.5076 - val_loss: 1.2584 - val_acc: 0.5143\n",
      "Epoch 71/300\n",
      " - 4s - loss: 1.2719 - acc: 0.5073 - val_loss: 1.2590 - val_acc: 0.5119\n",
      "Epoch 72/300\n",
      " - 4s - loss: 1.2716 - acc: 0.5093 - val_loss: 1.2592 - val_acc: 0.5098\n",
      "Epoch 73/300\n",
      " - 4s - loss: 1.2717 - acc: 0.5104 - val_loss: 1.2585 - val_acc: 0.5117\n",
      "Epoch 74/300\n",
      " - 4s - loss: 1.2706 - acc: 0.5075 - val_loss: 1.2605 - val_acc: 0.5170\n",
      "Epoch 75/300\n",
      " - 4s - loss: 1.2712 - acc: 0.5078 - val_loss: 1.2572 - val_acc: 0.5115\n",
      "Epoch 76/300\n",
      " - 4s - loss: 1.2714 - acc: 0.5102 - val_loss: 1.2643 - val_acc: 0.5055\n",
      "Epoch 77/300\n",
      " - 4s - loss: 1.2729 - acc: 0.5081 - val_loss: 1.2624 - val_acc: 0.5049\n",
      "Epoch 78/300\n",
      " - 4s - loss: 1.2693 - acc: 0.5091 - val_loss: 1.2605 - val_acc: 0.5139\n",
      "Epoch 79/300\n",
      " - 4s - loss: 1.2708 - acc: 0.5106 - val_loss: 1.2677 - val_acc: 0.5096\n",
      "Epoch 80/300\n",
      " - 4s - loss: 1.2709 - acc: 0.5096 - val_loss: 1.2601 - val_acc: 0.5162\n",
      "Epoch 81/300\n",
      " - 4s - loss: 1.2729 - acc: 0.5080 - val_loss: 1.2617 - val_acc: 0.5080\n",
      "Epoch 82/300\n",
      " - 4s - loss: 1.2717 - acc: 0.5081 - val_loss: 1.2572 - val_acc: 0.5108\n",
      "Epoch 83/300\n",
      " - 4s - loss: 1.2706 - acc: 0.5096 - val_loss: 1.2716 - val_acc: 0.5119\n",
      "Epoch 84/300\n",
      " - 4s - loss: 1.2709 - acc: 0.5061 - val_loss: 1.2756 - val_acc: 0.5102\n",
      "Epoch 85/300\n",
      " - 4s - loss: 1.2726 - acc: 0.5080 - val_loss: 1.2651 - val_acc: 0.5069\n",
      "Epoch 86/300\n",
      " - 4s - loss: 1.2689 - acc: 0.5093 - val_loss: 1.2561 - val_acc: 0.5137\n",
      "Epoch 87/300\n",
      " - 4s - loss: 1.2705 - acc: 0.5096 - val_loss: 1.2578 - val_acc: 0.5152\n",
      "Epoch 88/300\n",
      " - 4s - loss: 1.2698 - acc: 0.5087 - val_loss: 1.2618 - val_acc: 0.5154\n",
      "Epoch 89/300\n",
      " - 4s - loss: 1.2700 - acc: 0.5080 - val_loss: 1.2616 - val_acc: 0.5090\n",
      "Epoch 90/300\n",
      " - 4s - loss: 1.2694 - acc: 0.5099 - val_loss: 1.2730 - val_acc: 0.5108\n",
      "Epoch 91/300\n",
      " - 4s - loss: 1.2692 - acc: 0.5111 - val_loss: 1.2624 - val_acc: 0.5162\n",
      "Epoch 92/300\n",
      " - 4s - loss: 1.2701 - acc: 0.5087 - val_loss: 1.2553 - val_acc: 0.5185\n",
      "Epoch 93/300\n",
      " - 4s - loss: 1.2696 - acc: 0.5082 - val_loss: 1.2616 - val_acc: 0.5075\n",
      "Epoch 94/300\n",
      " - 4s - loss: 1.2701 - acc: 0.5079 - val_loss: 1.2563 - val_acc: 0.5172\n",
      "Epoch 95/300\n",
      " - 4s - loss: 1.2685 - acc: 0.5093 - val_loss: 1.2709 - val_acc: 0.5146\n",
      "Epoch 96/300\n",
      " - 4s - loss: 1.2683 - acc: 0.5102 - val_loss: 1.2643 - val_acc: 0.5119\n",
      "Epoch 97/300\n",
      " - 4s - loss: 1.2692 - acc: 0.5079 - val_loss: 1.2591 - val_acc: 0.5150\n",
      "Epoch 98/300\n",
      " - 4s - loss: 1.2698 - acc: 0.5089 - val_loss: 1.2549 - val_acc: 0.5150\n",
      "Epoch 99/300\n",
      " - 4s - loss: 1.2700 - acc: 0.5096 - val_loss: 1.2608 - val_acc: 0.5121\n",
      "Epoch 100/300\n",
      " - 4s - loss: 1.2700 - acc: 0.5078 - val_loss: 1.2589 - val_acc: 0.5127\n",
      "Epoch 101/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5075 - val_loss: 1.2628 - val_acc: 0.5090\n",
      "Epoch 102/300\n",
      " - 4s - loss: 1.2692 - acc: 0.5109 - val_loss: 1.2595 - val_acc: 0.5162\n",
      "Epoch 103/300\n",
      " - 4s - loss: 1.2706 - acc: 0.5087 - val_loss: 1.2556 - val_acc: 0.5146\n",
      "Epoch 104/300\n",
      " - 4s - loss: 1.2692 - acc: 0.5086 - val_loss: 1.2602 - val_acc: 0.5113\n",
      "Epoch 105/300\n",
      " - 4s - loss: 1.2690 - acc: 0.5112 - val_loss: 1.2586 - val_acc: 0.5092\n",
      "Epoch 106/300\n",
      " - 4s - loss: 1.2683 - acc: 0.5096 - val_loss: 1.2549 - val_acc: 0.5127\n",
      "Epoch 107/300\n",
      " - 4s - loss: 1.2693 - acc: 0.5103 - val_loss: 1.2563 - val_acc: 0.5172\n",
      "Epoch 108/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5093 - val_loss: 1.2568 - val_acc: 0.5154\n",
      "Epoch 109/300\n",
      " - 4s - loss: 1.2689 - acc: 0.5095 - val_loss: 1.2555 - val_acc: 0.5160\n",
      "Epoch 110/300\n",
      " - 4s - loss: 1.2681 - acc: 0.5091 - val_loss: 1.2563 - val_acc: 0.5127\n",
      "Epoch 111/300\n",
      " - 4s - loss: 1.2709 - acc: 0.5093 - val_loss: 1.2640 - val_acc: 0.5197\n",
      "Epoch 112/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5092 - val_loss: 1.2598 - val_acc: 0.5150\n",
      "Epoch 113/300\n",
      " - 4s - loss: 1.2681 - acc: 0.5106 - val_loss: 1.2601 - val_acc: 0.5172\n",
      "Epoch 114/300\n",
      " - 4s - loss: 1.2683 - acc: 0.5125 - val_loss: 1.2565 - val_acc: 0.5152\n",
      "Epoch 115/300\n",
      " - 4s - loss: 1.2681 - acc: 0.5100 - val_loss: 1.2589 - val_acc: 0.5084\n",
      "Epoch 116/300\n",
      " - 4s - loss: 1.2700 - acc: 0.5111 - val_loss: 1.2600 - val_acc: 0.5154\n",
      "Epoch 117/300\n",
      " - 4s - loss: 1.2702 - acc: 0.5079 - val_loss: 1.2579 - val_acc: 0.5117\n",
      "Epoch 118/300\n",
      " - 4s - loss: 1.2744 - acc: 0.5087 - val_loss: 1.2589 - val_acc: 0.5152\n",
      "Epoch 119/300\n",
      " - 4s - loss: 1.2732 - acc: 0.5093 - val_loss: 1.2568 - val_acc: 0.5113\n",
      "Epoch 120/300\n",
      " - 4s - loss: 1.2722 - acc: 0.5097 - val_loss: 1.2635 - val_acc: 0.5102\n",
      "Epoch 121/300\n",
      " - 4s - loss: 1.2730 - acc: 0.5097 - val_loss: 1.2861 - val_acc: 0.5075\n",
      "Epoch 122/300\n",
      " - 4s - loss: 1.2731 - acc: 0.5086 - val_loss: 1.2583 - val_acc: 0.5127\n",
      "Epoch 123/300\n",
      " - 4s - loss: 1.2697 - acc: 0.5113 - val_loss: 1.2794 - val_acc: 0.4985\n",
      "Epoch 124/300\n",
      " - 4s - loss: 1.2736 - acc: 0.5082 - val_loss: 1.2627 - val_acc: 0.5117\n",
      "Epoch 125/300\n",
      " - 4s - loss: 1.2730 - acc: 0.5087 - val_loss: 1.2583 - val_acc: 0.5111\n",
      "Epoch 126/300\n",
      " - 4s - loss: 1.2699 - acc: 0.5081 - val_loss: 1.2575 - val_acc: 0.5150\n",
      "Epoch 127/300\n",
      " - 4s - loss: 1.2722 - acc: 0.5083 - val_loss: 1.2738 - val_acc: 0.5090\n",
      "Epoch 128/300\n",
      " - 4s - loss: 1.2704 - acc: 0.5119 - val_loss: 1.2562 - val_acc: 0.5113\n",
      "Epoch 129/300\n",
      " - 4s - loss: 1.2686 - acc: 0.5107 - val_loss: 1.2600 - val_acc: 0.5094\n",
      "Epoch 130/300\n",
      " - 4s - loss: 1.2667 - acc: 0.5109 - val_loss: 1.2564 - val_acc: 0.5117\n",
      "Epoch 131/300\n",
      " - 4s - loss: 1.2693 - acc: 0.5100 - val_loss: 1.2577 - val_acc: 0.5162\n",
      "Epoch 132/300\n",
      " - 4s - loss: 1.2672 - acc: 0.5110 - val_loss: 1.2557 - val_acc: 0.5143\n",
      "Epoch 133/300\n",
      " - 4s - loss: 1.2703 - acc: 0.5090 - val_loss: 1.2569 - val_acc: 0.5110\n",
      "Epoch 134/300\n",
      " - 4s - loss: 1.2682 - acc: 0.5087 - val_loss: 1.2640 - val_acc: 0.5175\n",
      "Epoch 135/300\n",
      " - 4s - loss: 1.2692 - acc: 0.5075 - val_loss: 1.2607 - val_acc: 0.5148\n",
      "Epoch 136/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5081 - val_loss: 1.2555 - val_acc: 0.5129\n",
      "Epoch 137/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5094 - val_loss: 1.2559 - val_acc: 0.5154\n",
      "Epoch 138/300\n",
      " - 4s - loss: 1.2698 - acc: 0.5067 - val_loss: 1.2711 - val_acc: 0.5082\n",
      "Epoch 139/300\n",
      " - 4s - loss: 1.2696 - acc: 0.5087 - val_loss: 1.2591 - val_acc: 0.5156\n",
      "Epoch 140/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5111 - val_loss: 1.2546 - val_acc: 0.5119\n",
      "Epoch 141/300\n",
      " - 4s - loss: 1.2700 - acc: 0.5078 - val_loss: 1.2617 - val_acc: 0.5094\n",
      "Epoch 142/300\n",
      " - 4s - loss: 1.2670 - acc: 0.5106 - val_loss: 1.2571 - val_acc: 0.5127\n",
      "Epoch 143/300\n",
      " - 4s - loss: 1.2712 - acc: 0.5092 - val_loss: 1.2579 - val_acc: 0.5141\n",
      "Epoch 144/300\n",
      " - 4s - loss: 1.2682 - acc: 0.5129 - val_loss: 1.2571 - val_acc: 0.5135\n",
      "Epoch 145/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5099 - val_loss: 1.2685 - val_acc: 0.5086\n",
      "Epoch 146/300\n",
      " - 4s - loss: 1.2674 - acc: 0.5110 - val_loss: 1.2550 - val_acc: 0.5177\n",
      "Epoch 147/300\n",
      " - 4s - loss: 1.2709 - acc: 0.5102 - val_loss: 1.2547 - val_acc: 0.5156\n",
      "Epoch 148/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5119 - val_loss: 1.2567 - val_acc: 0.5139\n",
      "Epoch 149/300\n",
      " - 4s - loss: 1.2682 - acc: 0.5111 - val_loss: 1.2557 - val_acc: 0.5148\n",
      "Epoch 150/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5106 - val_loss: 1.2551 - val_acc: 0.5133\n",
      "Epoch 151/300\n",
      " - 4s - loss: 1.2679 - acc: 0.5087 - val_loss: 1.2552 - val_acc: 0.5146\n",
      "Epoch 152/300\n",
      " - 4s - loss: 1.2697 - acc: 0.5099 - val_loss: 1.2557 - val_acc: 0.5129\n",
      "Epoch 153/300\n",
      " - 4s - loss: 1.2686 - acc: 0.5114 - val_loss: 1.2570 - val_acc: 0.5088\n",
      "Epoch 154/300\n",
      " - 4s - loss: 1.2710 - acc: 0.5087 - val_loss: 1.2585 - val_acc: 0.5094\n",
      "Epoch 155/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5106 - val_loss: 1.2728 - val_acc: 0.5106\n",
      "Epoch 156/300\n",
      " - 4s - loss: 1.2690 - acc: 0.5094 - val_loss: 1.2565 - val_acc: 0.5131\n",
      "Epoch 157/300\n",
      " - 4s - loss: 1.2680 - acc: 0.5103 - val_loss: 1.2599 - val_acc: 0.5189\n",
      "Epoch 158/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5077 - val_loss: 1.2540 - val_acc: 0.5148\n",
      "Epoch 159/300\n",
      " - 4s - loss: 1.2675 - acc: 0.5111 - val_loss: 1.2719 - val_acc: 0.5053\n",
      "Epoch 160/300\n",
      " - 4s - loss: 1.2686 - acc: 0.5098 - val_loss: 1.2626 - val_acc: 0.5133\n",
      "Epoch 161/300\n",
      " - 4s - loss: 1.2657 - acc: 0.5118 - val_loss: 1.2590 - val_acc: 0.5174\n",
      "Epoch 162/300\n",
      " - 4s - loss: 1.2665 - acc: 0.5121 - val_loss: 1.2555 - val_acc: 0.5174\n",
      "Epoch 163/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5101 - val_loss: 1.2559 - val_acc: 0.5187\n",
      "Epoch 164/300\n",
      " - 4s - loss: 1.2692 - acc: 0.5098 - val_loss: 1.2546 - val_acc: 0.5168\n",
      "Epoch 165/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5116 - val_loss: 1.2565 - val_acc: 0.5160\n",
      "Epoch 166/300\n",
      " - 4s - loss: 1.2656 - acc: 0.5120 - val_loss: 1.2534 - val_acc: 0.5143\n",
      "Epoch 167/300\n",
      " - 4s - loss: 1.2683 - acc: 0.5103 - val_loss: 1.2589 - val_acc: 0.5148\n",
      "Epoch 168/300\n",
      " - 4s - loss: 1.2670 - acc: 0.5096 - val_loss: 1.2566 - val_acc: 0.5150\n",
      "Epoch 169/300\n",
      " - 4s - loss: 1.2667 - acc: 0.5100 - val_loss: 1.2612 - val_acc: 0.5183\n",
      "Epoch 170/300\n",
      " - 4s - loss: 1.2671 - acc: 0.5107 - val_loss: 1.2559 - val_acc: 0.5146\n",
      "Epoch 171/300\n",
      " - 4s - loss: 1.2685 - acc: 0.5096 - val_loss: 1.2566 - val_acc: 0.5152\n",
      "Epoch 172/300\n",
      " - 4s - loss: 1.2711 - acc: 0.5093 - val_loss: 1.2552 - val_acc: 0.5127\n",
      "Epoch 173/300\n",
      " - 4s - loss: 1.2683 - acc: 0.5090 - val_loss: 1.2681 - val_acc: 0.5108\n",
      "Epoch 174/300\n",
      " - 4s - loss: 1.2691 - acc: 0.5104 - val_loss: 1.2582 - val_acc: 0.5113\n",
      "Epoch 175/300\n",
      " - 4s - loss: 1.2673 - acc: 0.5084 - val_loss: 1.2546 - val_acc: 0.5154\n",
      "Epoch 176/300\n",
      " - 4s - loss: 1.2685 - acc: 0.5097 - val_loss: 1.2567 - val_acc: 0.5092\n",
      "Epoch 177/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5104 - val_loss: 1.2549 - val_acc: 0.5141\n",
      "Epoch 178/300\n",
      " - 4s - loss: 1.2734 - acc: 0.5091 - val_loss: 1.2609 - val_acc: 0.5113\n",
      "Epoch 179/300\n",
      " - 4s - loss: 1.2733 - acc: 0.5065 - val_loss: 1.2559 - val_acc: 0.5121\n",
      "Epoch 180/300\n",
      " - 4s - loss: 1.2724 - acc: 0.5103 - val_loss: 1.2568 - val_acc: 0.5098\n",
      "Epoch 181/300\n",
      " - 4s - loss: 1.2734 - acc: 0.5081 - val_loss: 1.2653 - val_acc: 0.5086\n",
      "Epoch 182/300\n",
      " - 4s - loss: 1.2693 - acc: 0.5107 - val_loss: 1.2559 - val_acc: 0.5170\n",
      "Epoch 183/300\n",
      " - 4s - loss: 1.2723 - acc: 0.5086 - val_loss: 1.2588 - val_acc: 0.5117\n",
      "Epoch 184/300\n",
      " - 4s - loss: 1.2694 - acc: 0.5104 - val_loss: 1.2676 - val_acc: 0.5104\n",
      "Epoch 185/300\n",
      " - 4s - loss: 1.2699 - acc: 0.5110 - val_loss: 1.2566 - val_acc: 0.5148\n",
      "Epoch 186/300\n",
      " - 4s - loss: 1.2722 - acc: 0.5083 - val_loss: 1.2579 - val_acc: 0.5102\n",
      "Epoch 187/300\n",
      " - 4s - loss: 1.2721 - acc: 0.5099 - val_loss: 1.2565 - val_acc: 0.5168\n",
      "Epoch 188/300\n",
      " - 4s - loss: 1.2707 - acc: 0.5080 - val_loss: 1.2559 - val_acc: 0.5154\n",
      "Epoch 189/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5088 - val_loss: 1.2589 - val_acc: 0.5166\n",
      "Epoch 190/300\n",
      " - 4s - loss: 1.2679 - acc: 0.5117 - val_loss: 1.2597 - val_acc: 0.5127\n",
      "Epoch 191/300\n",
      " - 4s - loss: 1.2704 - acc: 0.5089 - val_loss: 1.2609 - val_acc: 0.5141\n",
      "Epoch 192/300\n",
      " - 4s - loss: 1.2716 - acc: 0.5094 - val_loss: 1.2547 - val_acc: 0.5175\n",
      "Epoch 193/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5112 - val_loss: 1.2551 - val_acc: 0.5162\n",
      "Epoch 194/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5108 - val_loss: 1.2607 - val_acc: 0.5119\n",
      "Epoch 195/300\n",
      " - 4s - loss: 1.2692 - acc: 0.5101 - val_loss: 1.2566 - val_acc: 0.5131\n",
      "Epoch 196/300\n",
      " - 4s - loss: 1.2694 - acc: 0.5097 - val_loss: 1.2548 - val_acc: 0.5146\n",
      "Epoch 197/300\n",
      " - 4s - loss: 1.2664 - acc: 0.5091 - val_loss: 1.2600 - val_acc: 0.5096\n",
      "Epoch 198/300\n",
      " - 4s - loss: 1.2696 - acc: 0.5079 - val_loss: 1.2542 - val_acc: 0.5166\n",
      "Epoch 199/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5089 - val_loss: 1.2647 - val_acc: 0.5067\n",
      "Epoch 200/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5111 - val_loss: 1.2584 - val_acc: 0.5104\n",
      "Epoch 201/300\n",
      " - 4s - loss: 1.2676 - acc: 0.5112 - val_loss: 1.2666 - val_acc: 0.5135\n",
      "Epoch 202/300\n",
      " - 4s - loss: 1.2693 - acc: 0.5093 - val_loss: 1.2581 - val_acc: 0.5121\n",
      "Epoch 203/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5103 - val_loss: 1.2553 - val_acc: 0.5172\n",
      "Epoch 204/300\n",
      " - 4s - loss: 1.2666 - acc: 0.5106 - val_loss: 1.2578 - val_acc: 0.5133\n",
      "Epoch 205/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5113 - val_loss: 1.2561 - val_acc: 0.5185\n",
      "Epoch 206/300\n",
      " - 4s - loss: 1.2666 - acc: 0.5103 - val_loss: 1.2626 - val_acc: 0.5086\n",
      "Epoch 207/300\n",
      " - 4s - loss: 1.2677 - acc: 0.5111 - val_loss: 1.2593 - val_acc: 0.5189\n",
      "Epoch 208/300\n",
      " - 4s - loss: 1.2660 - acc: 0.5101 - val_loss: 1.2546 - val_acc: 0.5146\n",
      "Epoch 209/300\n",
      " - 4s - loss: 1.2688 - acc: 0.5108 - val_loss: 1.2555 - val_acc: 0.5160\n",
      "Epoch 210/300\n",
      " - 4s - loss: 1.2703 - acc: 0.5098 - val_loss: 1.2544 - val_acc: 0.5148\n",
      "Epoch 211/300\n",
      " - 4s - loss: 1.2685 - acc: 0.5112 - val_loss: 1.2567 - val_acc: 0.5111\n",
      "Epoch 212/300\n",
      " - 4s - loss: 1.2675 - acc: 0.5135 - val_loss: 1.2564 - val_acc: 0.5108\n",
      "Epoch 213/300\n",
      " - 4s - loss: 1.2685 - acc: 0.5090 - val_loss: 1.2544 - val_acc: 0.5144\n",
      "Epoch 214/300\n",
      " - 4s - loss: 1.2679 - acc: 0.5103 - val_loss: 1.2569 - val_acc: 0.5168\n",
      "Epoch 215/300\n",
      " - 4s - loss: 1.2683 - acc: 0.5137 - val_loss: 1.2573 - val_acc: 0.5144\n",
      "Epoch 216/300\n",
      " - 4s - loss: 1.2696 - acc: 0.5086 - val_loss: 1.2550 - val_acc: 0.5133\n",
      "Epoch 217/300\n",
      " - 4s - loss: 1.2691 - acc: 0.5088 - val_loss: 1.2766 - val_acc: 0.5077\n",
      "Epoch 218/300\n",
      " - 4s - loss: 1.2673 - acc: 0.5079 - val_loss: 1.2612 - val_acc: 0.5174\n",
      "Epoch 219/300\n",
      " - 4s - loss: 1.2666 - acc: 0.5111 - val_loss: 1.2596 - val_acc: 0.5144\n",
      "Epoch 220/300\n",
      " - 4s - loss: 1.2669 - acc: 0.5110 - val_loss: 1.2570 - val_acc: 0.5117\n",
      "Epoch 221/300\n",
      " - 4s - loss: 1.2707 - acc: 0.5095 - val_loss: 1.2564 - val_acc: 0.5139\n",
      "Epoch 222/300\n",
      " - 4s - loss: 1.2675 - acc: 0.5117 - val_loss: 1.2568 - val_acc: 0.5183\n",
      "Epoch 223/300\n",
      " - 4s - loss: 1.2677 - acc: 0.5097 - val_loss: 1.2643 - val_acc: 0.5127\n",
      "Epoch 224/300\n",
      " - 4s - loss: 1.2673 - acc: 0.5111 - val_loss: 1.2575 - val_acc: 0.5158\n",
      "Epoch 225/300\n",
      " - 4s - loss: 1.2673 - acc: 0.5116 - val_loss: 1.2539 - val_acc: 0.5170\n",
      "Epoch 226/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5091 - val_loss: 1.2569 - val_acc: 0.5150\n",
      "Epoch 227/300\n",
      " - 4s - loss: 1.2657 - acc: 0.5112 - val_loss: 1.2557 - val_acc: 0.5170\n",
      "Epoch 228/300\n",
      " - 4s - loss: 1.2673 - acc: 0.5104 - val_loss: 1.2567 - val_acc: 0.5125\n",
      "Epoch 229/300\n",
      " - 4s - loss: 1.2683 - acc: 0.5108 - val_loss: 1.2549 - val_acc: 0.5121\n",
      "Epoch 230/300\n",
      " - 4s - loss: 1.2684 - acc: 0.5126 - val_loss: 1.2560 - val_acc: 0.5185\n",
      "Epoch 231/300\n",
      " - 4s - loss: 1.2695 - acc: 0.5103 - val_loss: 1.2717 - val_acc: 0.5150\n",
      "Epoch 232/300\n",
      " - 4s - loss: 1.2686 - acc: 0.5107 - val_loss: 1.2616 - val_acc: 0.5125\n",
      "Epoch 233/300\n",
      " - 4s - loss: 1.2676 - acc: 0.5098 - val_loss: 1.2575 - val_acc: 0.5115\n",
      "Epoch 234/300\n",
      " - 4s - loss: 1.2689 - acc: 0.5106 - val_loss: 1.2597 - val_acc: 0.5079\n",
      "Epoch 235/300\n",
      " - 4s - loss: 1.2661 - acc: 0.5112 - val_loss: 1.2663 - val_acc: 0.5117\n",
      "Epoch 236/300\n",
      " - 4s - loss: 1.2697 - acc: 0.5099 - val_loss: 1.2545 - val_acc: 0.5144\n",
      "Epoch 237/300\n",
      " - 4s - loss: 1.2659 - acc: 0.5092 - val_loss: 1.2550 - val_acc: 0.5152\n",
      "Epoch 238/300\n",
      " - 4s - loss: 1.2681 - acc: 0.5098 - val_loss: 1.2570 - val_acc: 0.5119\n",
      "Epoch 239/300\n",
      " - 4s - loss: 1.2666 - acc: 0.5105 - val_loss: 1.2567 - val_acc: 0.5123\n",
      "Epoch 240/300\n",
      " - 4s - loss: 1.2680 - acc: 0.5089 - val_loss: 1.2567 - val_acc: 0.5181\n",
      "Epoch 241/300\n",
      " - 4s - loss: 1.2671 - acc: 0.5097 - val_loss: 1.2543 - val_acc: 0.5135\n",
      "Epoch 242/300\n",
      " - 4s - loss: 1.2673 - acc: 0.5103 - val_loss: 1.2601 - val_acc: 0.5156\n",
      "Epoch 243/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5110 - val_loss: 1.2547 - val_acc: 0.5152\n",
      "Epoch 244/300\n",
      " - 4s - loss: 1.2679 - acc: 0.5097 - val_loss: 1.2562 - val_acc: 0.5150\n",
      "Epoch 245/300\n",
      " - 4s - loss: 1.2674 - acc: 0.5118 - val_loss: 1.2570 - val_acc: 0.5179\n",
      "Epoch 246/300\n",
      " - 4s - loss: 1.2667 - acc: 0.5123 - val_loss: 1.2564 - val_acc: 0.5172\n",
      "Epoch 247/300\n",
      " - 4s - loss: 1.2668 - acc: 0.5100 - val_loss: 1.2541 - val_acc: 0.5156\n",
      "Epoch 248/300\n",
      " - 4s - loss: 1.2676 - acc: 0.5115 - val_loss: 1.2551 - val_acc: 0.5158\n",
      "Epoch 249/300\n",
      " - 4s - loss: 1.2670 - acc: 0.5110 - val_loss: 1.2598 - val_acc: 0.5166\n",
      "Epoch 250/300\n",
      " - 4s - loss: 1.2684 - acc: 0.5119 - val_loss: 1.2536 - val_acc: 0.5152\n",
      "Epoch 251/300\n",
      " - 4s - loss: 1.2691 - acc: 0.5103 - val_loss: 1.2633 - val_acc: 0.5073\n",
      "Epoch 252/300\n",
      " - 4s - loss: 1.2681 - acc: 0.5096 - val_loss: 1.2565 - val_acc: 0.5144\n",
      "Epoch 253/300\n",
      " - 4s - loss: 1.2675 - acc: 0.5125 - val_loss: 1.2579 - val_acc: 0.5181\n",
      "Epoch 254/300\n",
      " - 4s - loss: 1.2676 - acc: 0.5099 - val_loss: 1.2576 - val_acc: 0.5148\n",
      "Epoch 255/300\n",
      " - 4s - loss: 1.2674 - acc: 0.5085 - val_loss: 1.2536 - val_acc: 0.5158\n",
      "Epoch 256/300\n",
      " - 4s - loss: 1.2660 - acc: 0.5102 - val_loss: 1.2584 - val_acc: 0.5143\n",
      "Epoch 257/300\n",
      " - 4s - loss: 1.2675 - acc: 0.5095 - val_loss: 1.2563 - val_acc: 0.5119\n",
      "Epoch 258/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5096 - val_loss: 1.2551 - val_acc: 0.5175\n",
      "Epoch 259/300\n",
      " - 4s - loss: 1.2674 - acc: 0.5126 - val_loss: 1.2605 - val_acc: 0.5123\n",
      "Epoch 260/300\n",
      " - 4s - loss: 1.2653 - acc: 0.5126 - val_loss: 1.2547 - val_acc: 0.5146\n",
      "Epoch 261/300\n",
      " - 4s - loss: 1.2663 - acc: 0.5112 - val_loss: 1.2586 - val_acc: 0.5090\n",
      "Epoch 262/300\n",
      " - 4s - loss: 1.2686 - acc: 0.5128 - val_loss: 1.2569 - val_acc: 0.5172\n",
      "Epoch 263/300\n",
      " - 4s - loss: 1.2730 - acc: 0.5096 - val_loss: 1.2571 - val_acc: 0.5125\n",
      "Epoch 264/300\n",
      " - 4s - loss: 1.2711 - acc: 0.5098 - val_loss: 1.2629 - val_acc: 0.5086\n",
      "Epoch 265/300\n",
      " - 4s - loss: 1.2704 - acc: 0.5107 - val_loss: 1.2577 - val_acc: 0.5127\n",
      "Epoch 266/300\n",
      " - 4s - loss: 1.2697 - acc: 0.5097 - val_loss: 1.2574 - val_acc: 0.5154\n",
      "Epoch 267/300\n",
      " - 4s - loss: 1.2713 - acc: 0.5090 - val_loss: 1.2579 - val_acc: 0.5154\n",
      "Epoch 268/300\n",
      " - 4s - loss: 1.2711 - acc: 0.5094 - val_loss: 1.2742 - val_acc: 0.5098\n",
      "Epoch 269/300\n",
      " - 4s - loss: 1.2696 - acc: 0.5119 - val_loss: 1.2564 - val_acc: 0.5133\n",
      "Epoch 270/300\n",
      " - 4s - loss: 1.2699 - acc: 0.5101 - val_loss: 1.2619 - val_acc: 0.5088\n",
      "Epoch 271/300\n",
      " - 4s - loss: 1.2713 - acc: 0.5102 - val_loss: 1.2571 - val_acc: 0.5125\n",
      "Epoch 272/300\n",
      " - 4s - loss: 1.2696 - acc: 0.5101 - val_loss: 1.2595 - val_acc: 0.5150\n",
      "Epoch 273/300\n",
      " - 4s - loss: 1.2702 - acc: 0.5104 - val_loss: 1.2557 - val_acc: 0.5137\n",
      "Epoch 274/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5106 - val_loss: 1.2607 - val_acc: 0.5102\n",
      "Epoch 275/300\n",
      " - 4s - loss: 1.2701 - acc: 0.5106 - val_loss: 1.2581 - val_acc: 0.5170\n",
      "Epoch 276/300\n",
      " - 4s - loss: 1.2674 - acc: 0.5113 - val_loss: 1.2544 - val_acc: 0.5160\n",
      "Epoch 277/300\n",
      " - 4s - loss: 1.2700 - acc: 0.5104 - val_loss: 1.2563 - val_acc: 0.5137\n",
      "Epoch 278/300\n",
      " - 4s - loss: 1.2674 - acc: 0.5110 - val_loss: 1.2615 - val_acc: 0.5195\n",
      "Epoch 279/300\n",
      " - 4s - loss: 1.2682 - acc: 0.5098 - val_loss: 1.2623 - val_acc: 0.5150\n",
      "Epoch 280/300\n",
      " - 4s - loss: 1.2695 - acc: 0.5108 - val_loss: 1.2590 - val_acc: 0.5104\n",
      "Epoch 281/300\n",
      " - 4s - loss: 1.2691 - acc: 0.5102 - val_loss: 1.2574 - val_acc: 0.5183\n",
      "Epoch 282/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5116 - val_loss: 1.2549 - val_acc: 0.5158\n",
      "Epoch 283/300\n",
      " - 4s - loss: 1.2702 - acc: 0.5113 - val_loss: 1.2598 - val_acc: 0.5170\n",
      "Epoch 284/300\n",
      " - 4s - loss: 1.2717 - acc: 0.5085 - val_loss: 1.2561 - val_acc: 0.5137\n",
      "Epoch 285/300\n",
      " - 4s - loss: 1.2684 - acc: 0.5111 - val_loss: 1.2565 - val_acc: 0.5172\n",
      "Epoch 286/300\n",
      " - 4s - loss: 1.2674 - acc: 0.5110 - val_loss: 1.2566 - val_acc: 0.5160\n",
      "Epoch 287/300\n",
      " - 4s - loss: 1.2668 - acc: 0.5107 - val_loss: 1.2592 - val_acc: 0.5160\n",
      "Epoch 288/300\n",
      " - 4s - loss: 1.2687 - acc: 0.5114 - val_loss: 1.2620 - val_acc: 0.5162\n",
      "Epoch 289/300\n",
      " - 4s - loss: 1.2680 - acc: 0.5107 - val_loss: 1.2603 - val_acc: 0.5133\n",
      "Epoch 290/300\n",
      " - 4s - loss: 1.2684 - acc: 0.5120 - val_loss: 1.2612 - val_acc: 0.5181\n",
      "Epoch 291/300\n",
      " - 4s - loss: 1.2705 - acc: 0.5080 - val_loss: 1.2613 - val_acc: 0.5162\n",
      "Epoch 292/300\n",
      " - 4s - loss: 1.2675 - acc: 0.5110 - val_loss: 1.2656 - val_acc: 0.5053\n",
      "Epoch 293/300\n",
      " - 4s - loss: 1.2716 - acc: 0.5093 - val_loss: 1.2606 - val_acc: 0.5139\n",
      "Epoch 294/300\n",
      " - 4s - loss: 1.2693 - acc: 0.5113 - val_loss: 1.2562 - val_acc: 0.5146\n",
      "Epoch 295/300\n",
      " - 4s - loss: 1.2678 - acc: 0.5111 - val_loss: 1.2533 - val_acc: 0.5146\n",
      "Epoch 296/300\n",
      " - 4s - loss: 1.2673 - acc: 0.5112 - val_loss: 1.2553 - val_acc: 0.5135\n",
      "Epoch 297/300\n",
      " - 4s - loss: 1.2672 - acc: 0.5110 - val_loss: 1.2598 - val_acc: 0.5162\n",
      "Epoch 298/300\n",
      " - 4s - loss: 1.2676 - acc: 0.5109 - val_loss: 1.2590 - val_acc: 0.5189\n",
      "Epoch 299/300\n",
      " - 4s - loss: 1.2697 - acc: 0.5126 - val_loss: 1.2573 - val_acc: 0.5117\n",
      "Epoch 300/300\n",
      " - 4s - loss: 1.2668 - acc: 0.5121 - val_loss: 1.2552 - val_acc: 0.5121\n",
      "Final score (RMSE): 0.30173239814872077\n",
      "(20624, 7)\n",
      "(20624,)\n",
      "Accuracy train:  0.5061093871217999\n",
      "Final Test score (RMSE): 0.30169449271751764\n",
      "Accuracy test:  0.5045569129338763\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInitializing Keras\\n\")\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape = (input_shape_time,),  activation = 'relu', kernel_regularizer= regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(Dense(75, activation = 'relu',kernel_regularizer= regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(Dense(25, activation= 'relu', kernel_regularizer= regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(Dense(7,activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "monitor = EarlyStopping(monitor='loss', min_delta= 1e-3, patience = 5, verbose = 1, mode = 'auto' )\n",
    "\n",
    "#model.fit(X_train, np.array(train_labels_one_hot),callbacks = [monitor], verbose = 2, epochs = 25)\n",
    "history_time = model.fit(X_train_time, np.array(train_labels_one_hot_time), batch_size= 32, validation_data= (x_val_time, y_val_time),verbose = 2, epochs = 300)\n",
    "#history = model.fit_generator(X_train, steps_per_epoch = 100, epochs = 10, validation_data = np.array(train_labels_one_hot), verbose = 2, validation_steps = 50)\n",
    "pred = model.predict(X_train_time)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,train_labels_one_hot_time))\n",
    "print(f\"Final score (RMSE): {score}\")\n",
    "\n",
    "print(pred.shape)\n",
    "print(y_train_time.shape)\n",
    "corrects,wrongs = 0,0\n",
    "for i in range(len(pred)):\n",
    "    res = pred[i]\n",
    "    res_max = res.argmax()\n",
    "    if res_max == y_train_time[i]:\n",
    "        corrects += 1\n",
    "    else:\n",
    "        wrongs += 1\n",
    "        \n",
    "print(\"Accuracy train: \", corrects / (corrects + wrongs))\n",
    "\n",
    "pred = model.predict(X_test_time)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,test_labels_one_hot_time))\n",
    "print(f\"Final Test score (RMSE): {score}\")\n",
    "\n",
    "corrects,wrongs = 0,0\n",
    "for i in range(len(pred)):\n",
    "    res = pred[i]\n",
    "    res_max = res.argmax()\n",
    "    if res_max == y_test_time[i]:\n",
    "        corrects += 1\n",
    "    else:\n",
    "        wrongs += 1\n",
    "        \n",
    "print(\"Accuracy test: \", corrects / (corrects + wrongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "VkAVhvl7zo55",
    "outputId": "23216706-2a93-4115-ed58-6631ae83c857"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNqcNgVJK2Zw2BEopZXP/HyCdbCsgGVTmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(acc) + 1)\n",
    "\n",
    "acc_time = history_time.history['acc']\n",
    "val_acc_time = history_time.history['val_acc']\n",
    "loss_time = history_time.history['loss']\n",
    "val_loss_time = history_time.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, acc, 'b--', label = 'Training acc')\n",
    "plt.plot(epochs,acc_time, 'y--', label = 'Training acc with time' )\n",
    "plt.plot(epochs, val_acc, 'k--', label = 'Testing acc')\n",
    "plt.plot(epochs, val_acc_time, 'g--', label = 'Testing acc with time')\n",
    "plt.title('Accuracy test and train')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oJ7KCH1Jky6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Keras Intro fist network no overfitting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
